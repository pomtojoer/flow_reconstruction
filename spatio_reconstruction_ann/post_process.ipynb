{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "egyptian-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-ideal",
   "metadata": {},
   "source": [
    "# Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blind-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "interpolation_dirs = [1,2,3,4]\n",
    "\n",
    "for interpolation_dir in interpolation_dirs:\n",
    "    output_filepath = os.path.join(f'data_scaling/experiment_{interpolation_dir}', 'output.json')\n",
    "    config_filepath = os.path.join(f'data_scaling/experiment_{interpolation_dir}', 'config.json')\n",
    "    df = pd.read_json(output_filepath)\n",
    "    df = df.drop(columns=['counter'])\n",
    "    df = df.T\n",
    "    config_data = json.load(open(config_filepath))\n",
    "    df['experiment_num'] = interpolation_dir\n",
    "    frames.append(df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df = df.groupby('experiment_num').last().reset_index()\n",
    "case = ['Mean centring', 'Standardise', 'Normalise', 'Unscaled']\n",
    "df['case']=case\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beneficial-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Total prediction time [s]</th>\n",
       "      <th>Total prediction samples</th>\n",
       "      <th>Total training time [s]</th>\n",
       "      <th>Total epochs</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>Prediction time per sample [ms]</th>\n",
       "      <th>Time per epoch [s]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean centring</th>\n",
       "      <td>4.155801</td>\n",
       "      <td>12.396665</td>\n",
       "      <td>7.606181</td>\n",
       "      <td>0.179250</td>\n",
       "      <td>134.0</td>\n",
       "      <td>10.718322</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.337690</td>\n",
       "      <td>0.135675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardise</th>\n",
       "      <td>4.355911</td>\n",
       "      <td>15.380454</td>\n",
       "      <td>8.489679</td>\n",
       "      <td>0.150771</td>\n",
       "      <td>134.0</td>\n",
       "      <td>10.095597</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.125156</td>\n",
       "      <td>0.136427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalise</th>\n",
       "      <td>4.879248</td>\n",
       "      <td>16.002713</td>\n",
       "      <td>10.023962</td>\n",
       "      <td>0.151925</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11.504482</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.133768</td>\n",
       "      <td>0.133773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unscaled</th>\n",
       "      <td>21.365265</td>\n",
       "      <td>30.892900</td>\n",
       "      <td>25.739756</td>\n",
       "      <td>0.150079</td>\n",
       "      <td>134.0</td>\n",
       "      <td>13.531554</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.119996</td>\n",
       "      <td>0.132662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Min L2 error [%]  Max L2 error [%]  Mean L2 error [%]  \\\n",
       "case                                                                   \n",
       "Mean centring          4.155801         12.396665           7.606181   \n",
       "Standardise            4.355911         15.380454           8.489679   \n",
       "Normalise              4.879248         16.002713          10.023962   \n",
       "Unscaled              21.365265         30.892900          25.739756   \n",
       "\n",
       "               Total prediction time [s]  Total prediction samples  \\\n",
       "case                                                                 \n",
       "Mean centring                   0.179250                     134.0   \n",
       "Standardise                     0.150771                     134.0   \n",
       "Normalise                       0.151925                     134.0   \n",
       "Unscaled                        0.150079                     134.0   \n",
       "\n",
       "               Total training time [s]  Total epochs  experiment_num  \\\n",
       "case                                                                   \n",
       "Mean centring                10.718322          79.0               1   \n",
       "Standardise                  10.095597          74.0               2   \n",
       "Normalise                    11.504482          86.0               3   \n",
       "Unscaled                     13.531554         102.0               4   \n",
       "\n",
       "               Prediction time per sample [ms]  Time per epoch [s]  \n",
       "case                                                                \n",
       "Mean centring                         1.337690            0.135675  \n",
       "Standardise                           1.125156            0.136427  \n",
       "Normalise                             1.133768            0.133773  \n",
       "Unscaled                              1.119996            0.132662  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df[['min_l2_error','max_l2_error','mean_l2_error', 'total_prediction_time', 'total_prediction_samples', 'total_training_time', 'total_epochs', 'experiment_num','case']].set_index(['case'])\n",
    "df_val[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_val['prediction_time_per_sample'] = df_val['total_prediction_time'] / df_val['total_prediction_samples'] * 1000\n",
    "df_val['time_per_epoch'] = df_val['total_training_time'] / df_val['total_epochs']\n",
    "df_val = df_val.fillna('-')\n",
    "\n",
    "df_val = df_val.rename(columns={\n",
    "    'min_l2_error':'Min L2 error [%]',\n",
    "    'max_l2_error':'Max L2 error [%]',\n",
    "    'mean_l2_error':'Mean L2 error [%]',\n",
    "    'total_prediction_time':'Total prediction time [s]',\n",
    "    'total_prediction_samples':'Total prediction samples',\n",
    "    'prediction_time_per_sample':'Prediction time per sample [ms]',\n",
    "    'total_training_time':'Total training time [s]',\n",
    "    'total_epochs':'Total epochs',\n",
    "    'time_per_epoch': 'Time per epoch [s]'\n",
    "})\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "missing-football",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Min L2 error POD [%]</th>\n",
       "      <th>Max L2 error POD [%]</th>\n",
       "      <th>Mean L2 error POD [%]</th>\n",
       "      <th>experiment_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean centring</th>\n",
       "      <td>4.155801</td>\n",
       "      <td>12.396665</td>\n",
       "      <td>7.606181</td>\n",
       "      <td>20.475821</td>\n",
       "      <td>32.461318</td>\n",
       "      <td>24.177258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardise</th>\n",
       "      <td>4.355911</td>\n",
       "      <td>15.380454</td>\n",
       "      <td>8.489679</td>\n",
       "      <td>36.226417</td>\n",
       "      <td>46.089490</td>\n",
       "      <td>41.324178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalise</th>\n",
       "      <td>4.879248</td>\n",
       "      <td>16.002713</td>\n",
       "      <td>10.023962</td>\n",
       "      <td>75.402748</td>\n",
       "      <td>79.109004</td>\n",
       "      <td>77.401901</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unscaled</th>\n",
       "      <td>21.365265</td>\n",
       "      <td>30.892900</td>\n",
       "      <td>25.739756</td>\n",
       "      <td>20.524747</td>\n",
       "      <td>37.802247</td>\n",
       "      <td>28.098021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Min L2 error [%]  Max L2 error [%]  Mean L2 error [%]  \\\n",
       "case                                                                   \n",
       "Mean centring          4.155801         12.396665           7.606181   \n",
       "Standardise            4.355911         15.380454           8.489679   \n",
       "Normalise              4.879248         16.002713          10.023962   \n",
       "Unscaled              21.365265         30.892900          25.739756   \n",
       "\n",
       "               Min L2 error POD [%]  Max L2 error POD [%]  \\\n",
       "case                                                        \n",
       "Mean centring             20.475821             32.461318   \n",
       "Standardise               36.226417             46.089490   \n",
       "Normalise                 75.402748             79.109004   \n",
       "Unscaled                  20.524747             37.802247   \n",
       "\n",
       "               Mean L2 error POD [%]  experiment_num  \n",
       "case                                                  \n",
       "Mean centring              24.177258               1  \n",
       "Standardise                41.324178               2  \n",
       "Normalise                  77.401901               3  \n",
       "Unscaled                   28.098021               4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_err = df[['min_l2_error','max_l2_error','mean_l2_error', 'min_l2_error_pod','max_l2_error_pod','mean_l2_error_pod', 'experiment_num','case']].set_index(['case'])\n",
    "df_val_err[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_val_err[['min_l2_error_pod', 'max_l2_error_pod', 'mean_l2_error_pod']] *= 100\n",
    "df_val_err = df_val_err.fillna('-')\n",
    "\n",
    "df_val_err = df_val_err.rename(columns={\n",
    "    'min_l2_error':'Min L2 error [%]',\n",
    "    'max_l2_error':'Max L2 error [%]',\n",
    "    'mean_l2_error':'Mean L2 error [%]',\n",
    "    'min_l2_error_pod':'Min L2 error POD [%]',\n",
    "    'max_l2_error_pod':'Max L2 error POD [%]',\n",
    "    'mean_l2_error_pod':'Mean L2 error POD [%]',\n",
    "})\n",
    "df_val_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "according-keeping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean centring & 4.16\\% & 12.40\\% & 7.61\\% & 20.48\\% & 32.46\\% & 24.18\\% & 10.72 & 79 \\\\\n",
      "Standardise & 4.36\\% & 15.38\\% & 8.49\\% & 36.23\\% & 46.09\\% & 41.32\\% & 10.10 & 74 \\\\\n",
      "Normalise & 4.88\\% & 16.00\\% & 10.02\\% & 75.40\\% & 79.11\\% & 77.40\\% & 11.50 & 86 \\\\\n",
      "Unscaled & 21.37\\% & 30.89\\% & 25.74\\% & 20.52\\% & 37.80\\% & 28.10\\% & 13.53 & 102 \\\\\n"
     ]
    }
   ],
   "source": [
    "df_latex = df[['case','min_l2_error','max_l2_error','mean_l2_error', 'min_l2_error_pod','max_l2_error_pod','mean_l2_error_pod','total_training_time','total_epochs']]\n",
    "df_latex[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_latex[['min_l2_error_pod', 'max_l2_error_pod', 'mean_l2_error_pod']] *= 100\n",
    "\n",
    "val_idx = [key for key in df_latex.columns if key != 'case' and key != 'total_epochs']\n",
    "for idx, row in df_latex.iterrows():\n",
    "    output = row['case']\n",
    "    for val_idx_ in val_idx:\n",
    "        if val_idx_ != 'total_training_time':\n",
    "            output += f' & {row[val_idx_]:.2f}\\%'\n",
    "        else:\n",
    "            output += f' & {row[val_idx_]:.2f}'\n",
    "    output += f' & {row.total_epochs:.0f} \\\\\\\\'\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Total prediction time [s]</th>\n",
       "      <th>Total prediction samples</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>Prediction time per sample [ms]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean centring</th>\n",
       "      <td>[65.62, 100.58]</td>\n",
       "      <td>[99.62, 156.6]</td>\n",
       "      <td>[91.93, 106.36]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.54, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalise</th>\n",
       "      <td>[82.07, 100.5]</td>\n",
       "      <td>[100.47, 127.33]</td>\n",
       "      <td>[97.08, 102.49]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[0.54, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardise</th>\n",
       "      <td>[70.53, 99.6]</td>\n",
       "      <td>[99.6, 128.35]</td>\n",
       "      <td>[99.37, 102.98]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[0.54, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unscaled</th>\n",
       "      <td>[65.81, 105.55]</td>\n",
       "      <td>[104.52, 213.97]</td>\n",
       "      <td>[100.91, 125.0]</td>\n",
       "      <td>[0.21, 0.38]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>[0.54, 0.94]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Min L2 error [%]  Max L2 error [%] Mean L2 error [%]  \\\n",
       "case                                                                 \n",
       "Mean centring  [65.62, 100.58]    [99.62, 156.6]   [91.93, 106.36]   \n",
       "Normalise       [82.07, 100.5]  [100.47, 127.33]   [97.08, 102.49]   \n",
       "Standardise      [70.53, 99.6]    [99.6, 128.35]   [99.37, 102.98]   \n",
       "Unscaled       [65.81, 105.55]  [104.52, 213.97]   [100.91, 125.0]   \n",
       "\n",
       "              Total prediction time [s] Total prediction samples  \\\n",
       "case                                                               \n",
       "Mean centring              [0.22, 0.22]           [400.0, 400.0]   \n",
       "Normalise                  [0.22, 0.22]           [400.0, 400.0]   \n",
       "Standardise                [0.22, 0.22]           [400.0, 400.0]   \n",
       "Unscaled                   [0.21, 0.38]           [400.0, 400.0]   \n",
       "\n",
       "              experiment_num Prediction time per sample [ms]  \n",
       "case                                                          \n",
       "Mean centring         [1, 1]                    [0.54, 0.55]  \n",
       "Normalise             [3, 3]                    [0.54, 0.55]  \n",
       "Standardise           [2, 2]                    [0.54, 0.55]  \n",
       "Unscaled              [4, 4]                    [0.54, 0.94]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obstacles = [\"diamond_ar_1p25\",\n",
    "             \"diamond_ar_1p5\",\n",
    "             \"diamond_ar_1p66\",\n",
    "             \"diamond_ar_2p0\",\n",
    "             \"triangle_ar_1p25\",\n",
    "             \"triangle_ar_1p5\",\n",
    "             \"triangle_ar_1p66\",\n",
    "             \"triangle_ar_2p0\",\n",
    "             \"cylinder_half\",\n",
    "             \"cylinder_half_flipped\"]\n",
    "frames_test = []\n",
    "for obstacle in obstacles:\n",
    "    df_test = df[[f'{obstacle}_min_l2_error',f'{obstacle}_max_l2_error',f'{obstacle}_mean_l2_error',f'{obstacle}_total_prediction_time',f'{obstacle}_total_prediction_samples','experiment_num','case']].set_index(['case'])\n",
    "    df_test[[f'{obstacle}_min_l2_error',f'{obstacle}_max_l2_error',f'{obstacle}_mean_l2_error']] *= 100\n",
    "    df_test[f'{obstacle}_prediction_time_per_sample'] = df_test[f'{obstacle}_total_prediction_time'] / df_test[f'{obstacle}_total_prediction_samples'] * 1000\n",
    "    df_test = df_test.fillna('-')\n",
    "\n",
    "    df_test = df_test.rename(columns={\n",
    "        f'{obstacle}_min_l2_error':'Min L2 error [%]',\n",
    "        f'{obstacle}_max_l2_error':'Max L2 error [%]',\n",
    "        f'{obstacle}_mean_l2_error':'Mean L2 error [%]',\n",
    "        f'{obstacle}_total_prediction_time':'Total prediction time [s]',\n",
    "        f'{obstacle}_total_prediction_samples':'Total prediction samples',\n",
    "        f'{obstacle}_prediction_time_per_sample':'Prediction time per sample [ms]',\n",
    "    })\n",
    "    frames_test.append(df_test)\n",
    "\n",
    "df_test = pd.concat(frames_test)\n",
    "df_test_max = df_test.groupby(level=[0]).max()\n",
    "df_test_min = df_test.groupby(level=[0]).min()\n",
    "\n",
    "df_test_min_max = df_test_min.applymap(lambda x : [round(x,2)]) + df_test_max.applymap(lambda x : [round(x,2)])\n",
    "\n",
    "df_test_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funky-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean centring & 65.62\\% - 100.58\\% & 99.62\\% - 156.60\\% & 91.93\\% - 106.36\\% \\\\\n",
      "Normalise & 82.07\\% - 100.50\\% & 100.47\\% - 127.33\\% & 97.08\\% - 102.49\\% \\\\\n",
      "Standardise & 70.53\\% - 99.60\\% & 99.60\\% - 128.35\\% & 99.37\\% - 102.98\\% \\\\\n",
      "Unscaled & 65.81\\% - 105.55\\% & 104.52\\% - 213.97\\% & 100.91\\% - 125.00\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "df_latex = df_test_min_max.reset_index()[['case','Min L2 error [%]','Max L2 error [%]','Mean L2 error [%]']]\n",
    "\n",
    "val_idx = [key for key in df_latex.keys() if key != 'case']\n",
    "\n",
    "for idx, row in df_latex.iterrows():\n",
    "    output = row['case']\n",
    "    for val_idx_ in val_idx:\n",
    "        output += f' & {row[val_idx_][0]:.2f}\\% - {row[val_idx_][1]:.2f}\\%'\n",
    "    output += f' \\\\\\\\'\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-dollar",
   "metadata": {},
   "source": [
    "# Data scaling expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grave-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "interpolation_dirs = [1,2,3,4]\n",
    "\n",
    "for interpolation_dir in interpolation_dirs:\n",
    "    output_filepath = os.path.join(f'data_scaling_expanded/experiment_{interpolation_dir}', 'output.json')\n",
    "    config_filepath = os.path.join(f'data_scaling_expanded/experiment_{interpolation_dir}', 'config.json')\n",
    "    df = pd.read_json(output_filepath)\n",
    "    df = df.drop(columns=['counter'])\n",
    "    df = df.T\n",
    "    config_data = json.load(open(config_filepath))\n",
    "    df['experiment_num'] = interpolation_dir\n",
    "    frames.append(df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df = df.groupby('experiment_num').last().reset_index()\n",
    "case = ['Mean centring', 'Standardise', 'Normalise', 'Unscaled']\n",
    "df['case']=case\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-prisoner",
   "metadata": {},
   "source": [
    "# Sensor placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fossil-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "interpolation_dirs = [1,2]               # wall sensors\n",
    "interpolation_dirs += [3,4,5,6,7,8,9]    # line sensors\n",
    "interpolation_dirs += [10,11,12,13]      # T sensors\n",
    "interpolation_dirs += [14,15,16]         # patch sensors\n",
    "interpolation_dirs += [17,18,19]         # dense wall, line, patch sensors\n",
    "\n",
    "for interpolation_dir in interpolation_dirs:\n",
    "    \n",
    "    output_filepath = os.path.join(f'sensor_types/experiment_{interpolation_dir}', 'output.json')\n",
    "    config_filepath = os.path.join(f'sensor_types/experiment_{interpolation_dir}', 'config.json')\n",
    "    df = pd.read_json(output_filepath)\n",
    "    df = df.drop(columns=['counter'])\n",
    "    df = df.T\n",
    "    config_data = json.load(open(config_filepath))\n",
    "    df['experiment_num'] = interpolation_dir\n",
    "    frames.append(df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "case = ['W-1','W-2','L-1','L-2','L-3','L-4','L-5','L-6','L-7','T-1','T-2','T-3','T-4','P-1','P-2','P-3','W-3','L-8','P-4']\n",
    "df = df.groupby('experiment_num').last().reset_index()\n",
    "df['case']=case\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resident-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Total prediction time [s]</th>\n",
       "      <th>Total prediction samples</th>\n",
       "      <th>Total training time [s]</th>\n",
       "      <th>Total epochs</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>Prediction time per sample [ms]</th>\n",
       "      <th>Time per epoch [s]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W-1</th>\n",
       "      <td>2.893046</td>\n",
       "      <td>11.090328</td>\n",
       "      <td>6.612026</td>\n",
       "      <td>0.152773</td>\n",
       "      <td>134.0</td>\n",
       "      <td>12.872773</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.140100</td>\n",
       "      <td>0.132709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-2</th>\n",
       "      <td>3.557405</td>\n",
       "      <td>10.461475</td>\n",
       "      <td>6.939466</td>\n",
       "      <td>0.163070</td>\n",
       "      <td>134.0</td>\n",
       "      <td>15.213311</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.216940</td>\n",
       "      <td>0.130028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>2.577805</td>\n",
       "      <td>11.097012</td>\n",
       "      <td>6.227248</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11.422438</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.203654</td>\n",
       "      <td>0.134382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>4.679390</td>\n",
       "      <td>10.748733</td>\n",
       "      <td>7.083560</td>\n",
       "      <td>0.152653</td>\n",
       "      <td>134.0</td>\n",
       "      <td>12.949789</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.139201</td>\n",
       "      <td>0.132141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>3.383604</td>\n",
       "      <td>14.689366</td>\n",
       "      <td>8.059759</td>\n",
       "      <td>0.154742</td>\n",
       "      <td>134.0</td>\n",
       "      <td>10.637859</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.154795</td>\n",
       "      <td>0.136383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>4.022441</td>\n",
       "      <td>9.963559</td>\n",
       "      <td>6.805310</td>\n",
       "      <td>0.155095</td>\n",
       "      <td>134.0</td>\n",
       "      <td>13.075199</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.157428</td>\n",
       "      <td>0.133420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-5</th>\n",
       "      <td>3.057682</td>\n",
       "      <td>8.138382</td>\n",
       "      <td>5.447384</td>\n",
       "      <td>0.153610</td>\n",
       "      <td>134.0</td>\n",
       "      <td>9.683648</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.146340</td>\n",
       "      <td>0.138338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-6</th>\n",
       "      <td>3.724164</td>\n",
       "      <td>7.197103</td>\n",
       "      <td>5.517247</td>\n",
       "      <td>0.154597</td>\n",
       "      <td>134.0</td>\n",
       "      <td>9.038362</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.153711</td>\n",
       "      <td>0.139052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-7</th>\n",
       "      <td>2.701928</td>\n",
       "      <td>7.797504</td>\n",
       "      <td>5.328239</td>\n",
       "      <td>0.154214</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.796230</td>\n",
       "      <td>54.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.150852</td>\n",
       "      <td>0.144375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1</th>\n",
       "      <td>3.812580</td>\n",
       "      <td>8.571702</td>\n",
       "      <td>5.941066</td>\n",
       "      <td>0.173907</td>\n",
       "      <td>134.0</td>\n",
       "      <td>11.355075</td>\n",
       "      <td>86.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.297814</td>\n",
       "      <td>0.132036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-2</th>\n",
       "      <td>3.599321</td>\n",
       "      <td>8.942419</td>\n",
       "      <td>6.438730</td>\n",
       "      <td>0.174632</td>\n",
       "      <td>134.0</td>\n",
       "      <td>8.987880</td>\n",
       "      <td>66.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.303221</td>\n",
       "      <td>0.136180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-3</th>\n",
       "      <td>3.343837</td>\n",
       "      <td>10.461796</td>\n",
       "      <td>6.220339</td>\n",
       "      <td>0.173383</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.677952</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.293907</td>\n",
       "      <td>0.139599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-4</th>\n",
       "      <td>4.276222</td>\n",
       "      <td>8.842161</td>\n",
       "      <td>6.133717</td>\n",
       "      <td>0.180423</td>\n",
       "      <td>134.0</td>\n",
       "      <td>10.154085</td>\n",
       "      <td>75.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.346437</td>\n",
       "      <td>0.135388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-1</th>\n",
       "      <td>4.698585</td>\n",
       "      <td>14.550608</td>\n",
       "      <td>8.099495</td>\n",
       "      <td>0.177879</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.983222</td>\n",
       "      <td>57.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.327456</td>\n",
       "      <td>0.140057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-2</th>\n",
       "      <td>5.941808</td>\n",
       "      <td>14.416728</td>\n",
       "      <td>9.297816</td>\n",
       "      <td>0.184017</td>\n",
       "      <td>134.0</td>\n",
       "      <td>8.196201</td>\n",
       "      <td>57.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.373261</td>\n",
       "      <td>0.143793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-3</th>\n",
       "      <td>5.173573</td>\n",
       "      <td>9.431147</td>\n",
       "      <td>7.583921</td>\n",
       "      <td>0.154258</td>\n",
       "      <td>134.0</td>\n",
       "      <td>7.064005</td>\n",
       "      <td>49.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.151183</td>\n",
       "      <td>0.144163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-3</th>\n",
       "      <td>5.138693</td>\n",
       "      <td>12.422829</td>\n",
       "      <td>9.026829</td>\n",
       "      <td>0.158629</td>\n",
       "      <td>134.0</td>\n",
       "      <td>10.626042</td>\n",
       "      <td>78.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.183802</td>\n",
       "      <td>0.136231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-8</th>\n",
       "      <td>4.011612</td>\n",
       "      <td>13.277230</td>\n",
       "      <td>8.053790</td>\n",
       "      <td>0.156148</td>\n",
       "      <td>134.0</td>\n",
       "      <td>13.172901</td>\n",
       "      <td>98.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.165283</td>\n",
       "      <td>0.134417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-4</th>\n",
       "      <td>3.467418</td>\n",
       "      <td>11.634204</td>\n",
       "      <td>6.325172</td>\n",
       "      <td>0.178780</td>\n",
       "      <td>134.0</td>\n",
       "      <td>8.853169</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.334180</td>\n",
       "      <td>0.140526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Min L2 error [%]  Max L2 error [%]  Mean L2 error [%]  \\\n",
       "case                                                          \n",
       "W-1           2.893046         11.090328           6.612026   \n",
       "W-2           3.557405         10.461475           6.939466   \n",
       "L-1           2.577805         11.097012           6.227248   \n",
       "L-2           4.679390         10.748733           7.083560   \n",
       "L-3           3.383604         14.689366           8.059759   \n",
       "L-4           4.022441          9.963559           6.805310   \n",
       "L-5           3.057682          8.138382           5.447384   \n",
       "L-6           3.724164          7.197103           5.517247   \n",
       "L-7           2.701928          7.797504           5.328239   \n",
       "T-1           3.812580          8.571702           5.941066   \n",
       "T-2           3.599321          8.942419           6.438730   \n",
       "T-3           3.343837         10.461796           6.220339   \n",
       "T-4           4.276222          8.842161           6.133717   \n",
       "P-1           4.698585         14.550608           8.099495   \n",
       "P-2           5.941808         14.416728           9.297816   \n",
       "P-3           5.173573          9.431147           7.583921   \n",
       "W-3           5.138693         12.422829           9.026829   \n",
       "L-8           4.011612         13.277230           8.053790   \n",
       "P-4           3.467418         11.634204           6.325172   \n",
       "\n",
       "      Total prediction time [s]  Total prediction samples  \\\n",
       "case                                                        \n",
       "W-1                    0.152773                     134.0   \n",
       "W-2                    0.163070                     134.0   \n",
       "L-1                    0.161290                     134.0   \n",
       "L-2                    0.152653                     134.0   \n",
       "L-3                    0.154742                     134.0   \n",
       "L-4                    0.155095                     134.0   \n",
       "L-5                    0.153610                     134.0   \n",
       "L-6                    0.154597                     134.0   \n",
       "L-7                    0.154214                     134.0   \n",
       "T-1                    0.173907                     134.0   \n",
       "T-2                    0.174632                     134.0   \n",
       "T-3                    0.173383                     134.0   \n",
       "T-4                    0.180423                     134.0   \n",
       "P-1                    0.177879                     134.0   \n",
       "P-2                    0.184017                     134.0   \n",
       "P-3                    0.154258                     134.0   \n",
       "W-3                    0.158629                     134.0   \n",
       "L-8                    0.156148                     134.0   \n",
       "P-4                    0.178780                     134.0   \n",
       "\n",
       "      Total training time [s]  Total epochs  experiment_num  \\\n",
       "case                                                          \n",
       "W-1                 12.872773          97.0               1   \n",
       "W-2                 15.213311         117.0               2   \n",
       "L-1                 11.422438          85.0               3   \n",
       "L-2                 12.949789          98.0               4   \n",
       "L-3                 10.637859          78.0               5   \n",
       "L-4                 13.075199          98.0               6   \n",
       "L-5                  9.683648          70.0               7   \n",
       "L-6                  9.038362          65.0               8   \n",
       "L-7                  7.796230          54.0               9   \n",
       "T-1                 11.355075          86.0              10   \n",
       "T-2                  8.987880          66.0              11   \n",
       "T-3                  7.677952          55.0              12   \n",
       "T-4                 10.154085          75.0              13   \n",
       "P-1                  7.983222          57.0              14   \n",
       "P-2                  8.196201          57.0              15   \n",
       "P-3                  7.064005          49.0              16   \n",
       "W-3                 10.626042          78.0              17   \n",
       "L-8                 13.172901          98.0              18   \n",
       "P-4                  8.853169          63.0              19   \n",
       "\n",
       "      Prediction time per sample [ms]  Time per epoch [s]  \n",
       "case                                                       \n",
       "W-1                          1.140100            0.132709  \n",
       "W-2                          1.216940            0.130028  \n",
       "L-1                          1.203654            0.134382  \n",
       "L-2                          1.139201            0.132141  \n",
       "L-3                          1.154795            0.136383  \n",
       "L-4                          1.157428            0.133420  \n",
       "L-5                          1.146340            0.138338  \n",
       "L-6                          1.153711            0.139052  \n",
       "L-7                          1.150852            0.144375  \n",
       "T-1                          1.297814            0.132036  \n",
       "T-2                          1.303221            0.136180  \n",
       "T-3                          1.293907            0.139599  \n",
       "T-4                          1.346437            0.135388  \n",
       "P-1                          1.327456            0.140057  \n",
       "P-2                          1.373261            0.143793  \n",
       "P-3                          1.151183            0.144163  \n",
       "W-3                          1.183802            0.136231  \n",
       "L-8                          1.165283            0.134417  \n",
       "P-4                          1.334180            0.140526  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df[['min_l2_error','max_l2_error','mean_l2_error', 'total_prediction_time', 'total_prediction_samples', 'total_training_time', 'total_epochs', 'experiment_num','case']].set_index(['case'])\n",
    "df_val[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_val['prediction_time_per_sample'] = df_val['total_prediction_time'] / df_val['total_prediction_samples'] * 1000\n",
    "df_val['time_per_epoch'] = df_val['total_training_time'] / df_val['total_epochs']\n",
    "df_val = df_val.fillna('-')\n",
    "\n",
    "df_val = df_val.rename(columns={\n",
    "    'min_l2_error':'Min L2 error [%]',\n",
    "    'max_l2_error':'Max L2 error [%]',\n",
    "    'mean_l2_error':'Mean L2 error [%]',\n",
    "    'total_prediction_time':'Total prediction time [s]',\n",
    "    'total_prediction_samples':'Total prediction samples',\n",
    "    'prediction_time_per_sample':'Prediction time per sample [ms]',\n",
    "    'total_training_time':'Total training time [s]',\n",
    "    'total_epochs':'Total epochs',\n",
    "    'time_per_epoch': 'Time per epoch [s]'\n",
    "})\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "greater-president",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Min L2 error POD [%]</th>\n",
       "      <th>Max L2 error POD [%]</th>\n",
       "      <th>Mean L2 error POD [%]</th>\n",
       "      <th>experiment_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W-1</th>\n",
       "      <td>2.893046</td>\n",
       "      <td>11.090328</td>\n",
       "      <td>6.612026</td>\n",
       "      <td>21.434293</td>\n",
       "      <td>33.448398</td>\n",
       "      <td>24.011527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-2</th>\n",
       "      <td>3.557405</td>\n",
       "      <td>10.461475</td>\n",
       "      <td>6.939466</td>\n",
       "      <td>20.911056</td>\n",
       "      <td>48.080084</td>\n",
       "      <td>30.545841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>2.577805</td>\n",
       "      <td>11.097012</td>\n",
       "      <td>6.227248</td>\n",
       "      <td>20.552224</td>\n",
       "      <td>22.239563</td>\n",
       "      <td>21.286230</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>4.679390</td>\n",
       "      <td>10.748733</td>\n",
       "      <td>7.083560</td>\n",
       "      <td>22.312591</td>\n",
       "      <td>29.029689</td>\n",
       "      <td>25.293917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>3.383604</td>\n",
       "      <td>14.689366</td>\n",
       "      <td>8.059759</td>\n",
       "      <td>22.178594</td>\n",
       "      <td>45.151041</td>\n",
       "      <td>34.184988</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>4.022441</td>\n",
       "      <td>9.963559</td>\n",
       "      <td>6.805310</td>\n",
       "      <td>22.322519</td>\n",
       "      <td>46.531737</td>\n",
       "      <td>34.181055</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-5</th>\n",
       "      <td>3.057682</td>\n",
       "      <td>8.138382</td>\n",
       "      <td>5.447384</td>\n",
       "      <td>73.382761</td>\n",
       "      <td>105.685667</td>\n",
       "      <td>96.908662</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-6</th>\n",
       "      <td>3.724164</td>\n",
       "      <td>7.197103</td>\n",
       "      <td>5.517247</td>\n",
       "      <td>31.856470</td>\n",
       "      <td>104.508653</td>\n",
       "      <td>85.806529</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-7</th>\n",
       "      <td>2.701928</td>\n",
       "      <td>7.797504</td>\n",
       "      <td>5.328239</td>\n",
       "      <td>56.376064</td>\n",
       "      <td>104.787585</td>\n",
       "      <td>95.501989</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1</th>\n",
       "      <td>3.812580</td>\n",
       "      <td>8.571702</td>\n",
       "      <td>5.941066</td>\n",
       "      <td>20.603007</td>\n",
       "      <td>105.634926</td>\n",
       "      <td>78.197734</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-2</th>\n",
       "      <td>3.599321</td>\n",
       "      <td>8.942419</td>\n",
       "      <td>6.438730</td>\n",
       "      <td>4.790379</td>\n",
       "      <td>56.459831</td>\n",
       "      <td>36.577234</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-3</th>\n",
       "      <td>3.343837</td>\n",
       "      <td>10.461796</td>\n",
       "      <td>6.220339</td>\n",
       "      <td>8.330056</td>\n",
       "      <td>33.110301</td>\n",
       "      <td>18.840397</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-4</th>\n",
       "      <td>4.276222</td>\n",
       "      <td>8.842161</td>\n",
       "      <td>6.133717</td>\n",
       "      <td>8.406444</td>\n",
       "      <td>17.189308</td>\n",
       "      <td>12.587298</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-1</th>\n",
       "      <td>4.698585</td>\n",
       "      <td>14.550608</td>\n",
       "      <td>8.099495</td>\n",
       "      <td>4.018086</td>\n",
       "      <td>36.460829</td>\n",
       "      <td>22.481688</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-2</th>\n",
       "      <td>5.941808</td>\n",
       "      <td>14.416728</td>\n",
       "      <td>9.297816</td>\n",
       "      <td>0.335982</td>\n",
       "      <td>2.133268</td>\n",
       "      <td>0.895320</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-3</th>\n",
       "      <td>5.173573</td>\n",
       "      <td>9.431147</td>\n",
       "      <td>7.583921</td>\n",
       "      <td>1.058383</td>\n",
       "      <td>6.227065</td>\n",
       "      <td>3.428323</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-3</th>\n",
       "      <td>5.138693</td>\n",
       "      <td>12.422829</td>\n",
       "      <td>9.026829</td>\n",
       "      <td>2.419607</td>\n",
       "      <td>17.264879</td>\n",
       "      <td>10.543959</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-8</th>\n",
       "      <td>4.011612</td>\n",
       "      <td>13.277230</td>\n",
       "      <td>8.053790</td>\n",
       "      <td>12.010326</td>\n",
       "      <td>38.027851</td>\n",
       "      <td>23.157326</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-4</th>\n",
       "      <td>3.467418</td>\n",
       "      <td>11.634204</td>\n",
       "      <td>6.325172</td>\n",
       "      <td>3.961776</td>\n",
       "      <td>26.649542</td>\n",
       "      <td>17.460263</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Min L2 error [%]  Max L2 error [%]  Mean L2 error [%]  \\\n",
       "case                                                          \n",
       "W-1           2.893046         11.090328           6.612026   \n",
       "W-2           3.557405         10.461475           6.939466   \n",
       "L-1           2.577805         11.097012           6.227248   \n",
       "L-2           4.679390         10.748733           7.083560   \n",
       "L-3           3.383604         14.689366           8.059759   \n",
       "L-4           4.022441          9.963559           6.805310   \n",
       "L-5           3.057682          8.138382           5.447384   \n",
       "L-6           3.724164          7.197103           5.517247   \n",
       "L-7           2.701928          7.797504           5.328239   \n",
       "T-1           3.812580          8.571702           5.941066   \n",
       "T-2           3.599321          8.942419           6.438730   \n",
       "T-3           3.343837         10.461796           6.220339   \n",
       "T-4           4.276222          8.842161           6.133717   \n",
       "P-1           4.698585         14.550608           8.099495   \n",
       "P-2           5.941808         14.416728           9.297816   \n",
       "P-3           5.173573          9.431147           7.583921   \n",
       "W-3           5.138693         12.422829           9.026829   \n",
       "L-8           4.011612         13.277230           8.053790   \n",
       "P-4           3.467418         11.634204           6.325172   \n",
       "\n",
       "      Min L2 error POD [%]  Max L2 error POD [%]  Mean L2 error POD [%]  \\\n",
       "case                                                                      \n",
       "W-1              21.434293             33.448398              24.011527   \n",
       "W-2              20.911056             48.080084              30.545841   \n",
       "L-1              20.552224             22.239563              21.286230   \n",
       "L-2              22.312591             29.029689              25.293917   \n",
       "L-3              22.178594             45.151041              34.184988   \n",
       "L-4              22.322519             46.531737              34.181055   \n",
       "L-5              73.382761            105.685667              96.908662   \n",
       "L-6              31.856470            104.508653              85.806529   \n",
       "L-7              56.376064            104.787585              95.501989   \n",
       "T-1              20.603007            105.634926              78.197734   \n",
       "T-2               4.790379             56.459831              36.577234   \n",
       "T-3               8.330056             33.110301              18.840397   \n",
       "T-4               8.406444             17.189308              12.587298   \n",
       "P-1               4.018086             36.460829              22.481688   \n",
       "P-2               0.335982              2.133268               0.895320   \n",
       "P-3               1.058383              6.227065               3.428323   \n",
       "W-3               2.419607             17.264879              10.543959   \n",
       "L-8              12.010326             38.027851              23.157326   \n",
       "P-4               3.961776             26.649542              17.460263   \n",
       "\n",
       "      experiment_num  \n",
       "case                  \n",
       "W-1                1  \n",
       "W-2                2  \n",
       "L-1                3  \n",
       "L-2                4  \n",
       "L-3                5  \n",
       "L-4                6  \n",
       "L-5                7  \n",
       "L-6                8  \n",
       "L-7                9  \n",
       "T-1               10  \n",
       "T-2               11  \n",
       "T-3               12  \n",
       "T-4               13  \n",
       "P-1               14  \n",
       "P-2               15  \n",
       "P-3               16  \n",
       "W-3               17  \n",
       "L-8               18  \n",
       "P-4               19  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_err = df[['min_l2_error','max_l2_error','mean_l2_error', 'min_l2_error_pod','max_l2_error_pod','mean_l2_error_pod', 'experiment_num','case']].set_index(['case'])\n",
    "df_val_err[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_val_err[['min_l2_error_pod', 'max_l2_error_pod', 'mean_l2_error_pod']] *= 100\n",
    "df_val_err = df_val_err.fillna('-')\n",
    "\n",
    "df_val_err = df_val_err.rename(columns={\n",
    "    'min_l2_error':'Min L2 error [%]',\n",
    "    'max_l2_error':'Max L2 error [%]',\n",
    "    'mean_l2_error':'Mean L2 error [%]',\n",
    "    'min_l2_error_pod':'Min L2 error POD [%]',\n",
    "    'max_l2_error_pod':'Max L2 error POD [%]',\n",
    "    'mean_l2_error_pod':'Mean L2 error POD [%]',\n",
    "})\n",
    "df_val_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "after-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-1 & 2.89\\% & 11.09\\% & 6.61\\% & 21.43\\% & 33.45\\% & 24.01\\% & 12.87 & 97 \\\\\n",
      "W-2 & 3.56\\% & 10.46\\% & 6.94\\% & 20.91\\% & 48.08\\% & 30.55\\% & 15.21 & 117 \\\\\n",
      "L-1 & 2.58\\% & 11.10\\% & 6.23\\% & 20.55\\% & 22.24\\% & 21.29\\% & 11.42 & 85 \\\\\n",
      "L-2 & 4.68\\% & 10.75\\% & 7.08\\% & 22.31\\% & 29.03\\% & 25.29\\% & 12.95 & 98 \\\\\n",
      "L-3 & 3.38\\% & 14.69\\% & 8.06\\% & 22.18\\% & 45.15\\% & 34.18\\% & 10.64 & 78 \\\\\n",
      "L-4 & 4.02\\% & 9.96\\% & 6.81\\% & 22.32\\% & 46.53\\% & 34.18\\% & 13.08 & 98 \\\\\n",
      "L-5 & 3.06\\% & 8.14\\% & 5.45\\% & 73.38\\% & 105.69\\% & 96.91\\% & 9.68 & 70 \\\\\n",
      "L-6 & 3.72\\% & 7.20\\% & 5.52\\% & 31.86\\% & 104.51\\% & 85.81\\% & 9.04 & 65 \\\\\n",
      "L-7 & 2.70\\% & 7.80\\% & 5.33\\% & 56.38\\% & 104.79\\% & 95.50\\% & 7.80 & 54 \\\\\n",
      "T-1 & 3.81\\% & 8.57\\% & 5.94\\% & 20.60\\% & 105.63\\% & 78.20\\% & 11.36 & 86 \\\\\n",
      "T-2 & 3.60\\% & 8.94\\% & 6.44\\% & 4.79\\% & 56.46\\% & 36.58\\% & 8.99 & 66 \\\\\n",
      "T-3 & 3.34\\% & 10.46\\% & 6.22\\% & 8.33\\% & 33.11\\% & 18.84\\% & 7.68 & 55 \\\\\n",
      "T-4 & 4.28\\% & 8.84\\% & 6.13\\% & 8.41\\% & 17.19\\% & 12.59\\% & 10.15 & 75 \\\\\n",
      "P-1 & 4.70\\% & 14.55\\% & 8.10\\% & 4.02\\% & 36.46\\% & 22.48\\% & 7.98 & 57 \\\\\n",
      "P-2 & 5.94\\% & 14.42\\% & 9.30\\% & 0.34\\% & 2.13\\% & 0.90\\% & 8.20 & 57 \\\\\n",
      "P-3 & 5.17\\% & 9.43\\% & 7.58\\% & 1.06\\% & 6.23\\% & 3.43\\% & 7.06 & 49 \\\\\n",
      "W-3 & 5.14\\% & 12.42\\% & 9.03\\% & 2.42\\% & 17.26\\% & 10.54\\% & 10.63 & 78 \\\\\n",
      "L-8 & 4.01\\% & 13.28\\% & 8.05\\% & 12.01\\% & 38.03\\% & 23.16\\% & 13.17 & 98 \\\\\n",
      "P-4 & 3.47\\% & 11.63\\% & 6.33\\% & 3.96\\% & 26.65\\% & 17.46\\% & 8.85 & 63 \\\\\n"
     ]
    }
   ],
   "source": [
    "df_latex = df[['case','min_l2_error','max_l2_error','mean_l2_error','min_l2_error_pod','max_l2_error_pod','mean_l2_error_pod','total_training_time','total_epochs']]\n",
    "df_latex[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_latex[['min_l2_error_pod', 'max_l2_error_pod', 'mean_l2_error_pod']] *= 100\n",
    "\n",
    "val_idx = [key for key in df_latex.columns if key != 'case' and key != 'total_epochs']\n",
    "for idx, row in df_latex.iterrows():\n",
    "    output = row['case']\n",
    "    for val_idx_ in val_idx:\n",
    "        if val_idx_ != 'total_training_time':\n",
    "            output += f' & {row[val_idx_]:.2f}\\%'\n",
    "        else:\n",
    "            output += f' & {row[val_idx_]:.2f}'\n",
    "    output += f' & {row.total_epochs:.0f} \\\\\\\\'\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chinese-mouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Total prediction time [s]</th>\n",
       "      <th>Total prediction samples</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>Prediction time per sample [ms]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>[96.04, 96.04]</td>\n",
       "      <td>[96.04, 96.04]</td>\n",
       "      <td>[96.04, 96.04]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>[104.54, 104.54]</td>\n",
       "      <td>[104.54, 104.54]</td>\n",
       "      <td>[104.54, 104.54]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>[98.87, 98.87]</td>\n",
       "      <td>[98.87, 98.87]</td>\n",
       "      <td>[98.87, 98.87]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>[98.2, 98.2]</td>\n",
       "      <td>[98.2, 98.2]</td>\n",
       "      <td>[98.2, 98.2]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-5</th>\n",
       "      <td>[96.49, 96.49]</td>\n",
       "      <td>[96.49, 96.49]</td>\n",
       "      <td>[96.49, 96.49]</td>\n",
       "      <td>[0.36, 0.36]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[7, 7]</td>\n",
       "      <td>[0.89, 0.89]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-6</th>\n",
       "      <td>[98.93, 98.93]</td>\n",
       "      <td>[98.93, 98.93]</td>\n",
       "      <td>[98.93, 98.93]</td>\n",
       "      <td>[0.36, 0.36]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>[0.89, 0.89]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-7</th>\n",
       "      <td>[96.91, 96.91]</td>\n",
       "      <td>[96.91, 96.91]</td>\n",
       "      <td>[96.91, 96.91]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[9, 9]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-8</th>\n",
       "      <td>[98.28, 98.28]</td>\n",
       "      <td>[98.28, 98.28]</td>\n",
       "      <td>[98.28, 98.28]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[18, 18]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-1</th>\n",
       "      <td>[95.56, 95.56]</td>\n",
       "      <td>[95.56, 95.56]</td>\n",
       "      <td>[95.56, 95.56]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[14, 14]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-2</th>\n",
       "      <td>[97.26, 97.26]</td>\n",
       "      <td>[97.26, 97.26]</td>\n",
       "      <td>[97.26, 97.26]</td>\n",
       "      <td>[0.37, 0.37]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>[0.93, 0.93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-3</th>\n",
       "      <td>[96.91, 96.91]</td>\n",
       "      <td>[96.91, 96.91]</td>\n",
       "      <td>[96.91, 96.91]</td>\n",
       "      <td>[0.24, 0.24]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[16, 16]</td>\n",
       "      <td>[0.59, 0.59]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-4</th>\n",
       "      <td>[100.48, 100.48]</td>\n",
       "      <td>[100.49, 100.49]</td>\n",
       "      <td>[100.48, 100.48]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[19, 19]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1</th>\n",
       "      <td>[96.53, 96.53]</td>\n",
       "      <td>[96.53, 96.53]</td>\n",
       "      <td>[96.53, 96.53]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-2</th>\n",
       "      <td>[100.75, 100.75]</td>\n",
       "      <td>[100.75, 100.75]</td>\n",
       "      <td>[100.75, 100.75]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-3</th>\n",
       "      <td>[99.74, 99.74]</td>\n",
       "      <td>[99.74, 99.74]</td>\n",
       "      <td>[99.74, 99.74]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[12, 12]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-4</th>\n",
       "      <td>[96.72, 96.72]</td>\n",
       "      <td>[96.72, 96.72]</td>\n",
       "      <td>[96.72, 96.72]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[13, 13]</td>\n",
       "      <td>[0.53, 0.53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-1</th>\n",
       "      <td>[99.15, 99.15]</td>\n",
       "      <td>[99.15, 99.15]</td>\n",
       "      <td>[99.15, 99.15]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-2</th>\n",
       "      <td>[98.17, 98.17]</td>\n",
       "      <td>[98.17, 98.17]</td>\n",
       "      <td>[98.17, 98.17]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-3</th>\n",
       "      <td>[100.47, 100.47]</td>\n",
       "      <td>[100.47, 100.47]</td>\n",
       "      <td>[100.47, 100.47]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[17, 17]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Min L2 error [%]  Max L2 error [%] Mean L2 error [%]  \\\n",
       "case                                                         \n",
       "L-1     [96.04, 96.04]    [96.04, 96.04]    [96.04, 96.04]   \n",
       "L-2   [104.54, 104.54]  [104.54, 104.54]  [104.54, 104.54]   \n",
       "L-3     [98.87, 98.87]    [98.87, 98.87]    [98.87, 98.87]   \n",
       "L-4       [98.2, 98.2]      [98.2, 98.2]      [98.2, 98.2]   \n",
       "L-5     [96.49, 96.49]    [96.49, 96.49]    [96.49, 96.49]   \n",
       "L-6     [98.93, 98.93]    [98.93, 98.93]    [98.93, 98.93]   \n",
       "L-7     [96.91, 96.91]    [96.91, 96.91]    [96.91, 96.91]   \n",
       "L-8     [98.28, 98.28]    [98.28, 98.28]    [98.28, 98.28]   \n",
       "P-1     [95.56, 95.56]    [95.56, 95.56]    [95.56, 95.56]   \n",
       "P-2     [97.26, 97.26]    [97.26, 97.26]    [97.26, 97.26]   \n",
       "P-3     [96.91, 96.91]    [96.91, 96.91]    [96.91, 96.91]   \n",
       "P-4   [100.48, 100.48]  [100.49, 100.49]  [100.48, 100.48]   \n",
       "T-1     [96.53, 96.53]    [96.53, 96.53]    [96.53, 96.53]   \n",
       "T-2   [100.75, 100.75]  [100.75, 100.75]  [100.75, 100.75]   \n",
       "T-3     [99.74, 99.74]    [99.74, 99.74]    [99.74, 99.74]   \n",
       "T-4     [96.72, 96.72]    [96.72, 96.72]    [96.72, 96.72]   \n",
       "W-1     [99.15, 99.15]    [99.15, 99.15]    [99.15, 99.15]   \n",
       "W-2     [98.17, 98.17]    [98.17, 98.17]    [98.17, 98.17]   \n",
       "W-3   [100.47, 100.47]  [100.47, 100.47]  [100.47, 100.47]   \n",
       "\n",
       "     Total prediction time [s] Total prediction samples experiment_num  \\\n",
       "case                                                                     \n",
       "L-1               [0.22, 0.22]           [400.0, 400.0]         [3, 3]   \n",
       "L-2               [0.22, 0.22]           [400.0, 400.0]         [4, 4]   \n",
       "L-3               [0.22, 0.22]           [400.0, 400.0]         [5, 5]   \n",
       "L-4               [0.22, 0.22]           [400.0, 400.0]         [6, 6]   \n",
       "L-5               [0.36, 0.36]           [400.0, 400.0]         [7, 7]   \n",
       "L-6               [0.36, 0.36]           [400.0, 400.0]         [8, 8]   \n",
       "L-7               [0.22, 0.22]           [400.0, 400.0]         [9, 9]   \n",
       "L-8               [0.22, 0.22]           [400.0, 400.0]       [18, 18]   \n",
       "P-1               [0.21, 0.21]           [400.0, 400.0]       [14, 14]   \n",
       "P-2               [0.37, 0.37]           [400.0, 400.0]       [15, 15]   \n",
       "P-3               [0.24, 0.24]           [400.0, 400.0]       [16, 16]   \n",
       "P-4               [0.21, 0.21]           [400.0, 400.0]       [19, 19]   \n",
       "T-1               [0.21, 0.21]           [400.0, 400.0]       [10, 10]   \n",
       "T-2               [0.21, 0.21]           [400.0, 400.0]       [11, 11]   \n",
       "T-3               [0.22, 0.22]           [400.0, 400.0]       [12, 12]   \n",
       "T-4               [0.21, 0.21]           [400.0, 400.0]       [13, 13]   \n",
       "W-1               [0.22, 0.22]           [400.0, 400.0]         [1, 1]   \n",
       "W-2               [0.22, 0.22]           [400.0, 400.0]         [2, 2]   \n",
       "W-3               [0.22, 0.22]           [400.0, 400.0]       [17, 17]   \n",
       "\n",
       "     Prediction time per sample [ms]  \n",
       "case                                  \n",
       "L-1                     [0.54, 0.54]  \n",
       "L-2                     [0.54, 0.54]  \n",
       "L-3                     [0.54, 0.54]  \n",
       "L-4                     [0.54, 0.54]  \n",
       "L-5                     [0.89, 0.89]  \n",
       "L-6                     [0.89, 0.89]  \n",
       "L-7                     [0.54, 0.54]  \n",
       "L-8                     [0.54, 0.54]  \n",
       "P-1                     [0.54, 0.54]  \n",
       "P-2                     [0.93, 0.93]  \n",
       "P-3                     [0.59, 0.59]  \n",
       "P-4                     [0.54, 0.54]  \n",
       "T-1                     [0.54, 0.54]  \n",
       "T-2                     [0.54, 0.54]  \n",
       "T-3                     [0.54, 0.54]  \n",
       "T-4                     [0.53, 0.53]  \n",
       "W-1                     [0.55, 0.55]  \n",
       "W-2                     [0.54, 0.54]  \n",
       "W-3                     [0.54, 0.54]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obstacles = [\"diamond_ar_1p25\",\n",
    "             \"diamond_ar_1p5\",\n",
    "             \"diamond_ar_1p66\",\n",
    "             \"diamond_ar_2p0\",\n",
    "             \"triangle_ar_1p25\",\n",
    "             \"triangle_ar_1p5\",\n",
    "             \"triangle_ar_1p66\",\n",
    "             \"triangle_ar_2p0\",\n",
    "             \"cylinder_half\",\n",
    "             \"cylinder_half_flipped\"]\n",
    "\n",
    "obstacles = [\"diamond_ar_2p0\"]\n",
    "\n",
    "frames_test = []\n",
    "for obstacle in obstacles:\n",
    "    df_test = df[[f'{obstacle}_min_l2_error',f'{obstacle}_max_l2_error',f'{obstacle}_mean_l2_error',f'{obstacle}_total_prediction_time',f'{obstacle}_total_prediction_samples','experiment_num','case']].set_index(['case'])\n",
    "    df_test[[f'{obstacle}_min_l2_error',f'{obstacle}_max_l2_error',f'{obstacle}_mean_l2_error']] *= 100\n",
    "    df_test[f'{obstacle}_prediction_time_per_sample'] = df_test[f'{obstacle}_total_prediction_time'] / df_test[f'{obstacle}_total_prediction_samples'] * 1000\n",
    "    df_test = df_test.fillna('-')\n",
    "\n",
    "    df_test = df_test.rename(columns={\n",
    "        f'{obstacle}_min_l2_error':'Min L2 error [%]',\n",
    "        f'{obstacle}_max_l2_error':'Max L2 error [%]',\n",
    "        f'{obstacle}_mean_l2_error':'Mean L2 error [%]',\n",
    "        f'{obstacle}_total_prediction_time':'Total prediction time [s]',\n",
    "        f'{obstacle}_total_prediction_samples':'Total prediction samples',\n",
    "        f'{obstacle}_prediction_time_per_sample':'Prediction time per sample [ms]',\n",
    "    })\n",
    "    frames_test.append(df_test)\n",
    "\n",
    "df_test = pd.concat(frames_test)\n",
    "df_test_max = df_test.groupby(level=[0]).max()\n",
    "df_test_min = df_test.groupby(level=[0]).min()\n",
    "\n",
    "df_test_min_max = df_test_min.applymap(lambda x : [round(x,2)]) + df_test_max.applymap(lambda x : [round(x,2)])\n",
    "\n",
    "df_test_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "artificial-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-1 & 96.04\\% & 96.04\\% & 96.04\\%\n",
      "L-2 & 104.54\\% & 104.54\\% & 104.54\\%\n",
      "L-3 & 98.87\\% & 98.87\\% & 98.87\\%\n",
      "L-4 & 98.20\\% & 98.20\\% & 98.20\\%\n",
      "L-5 & 96.49\\% & 96.49\\% & 96.49\\%\n",
      "L-6 & 98.93\\% & 98.93\\% & 98.93\\%\n",
      "L-7 & 96.91\\% & 96.91\\% & 96.91\\%\n",
      "L-8 & 98.28\\% & 98.28\\% & 98.28\\%\n",
      "P-1 & 95.56\\% & 95.56\\% & 95.56\\%\n",
      "P-2 & 97.26\\% & 97.26\\% & 97.26\\%\n",
      "P-3 & 96.91\\% & 96.91\\% & 96.91\\%\n",
      "P-4 & 100.48\\% & 100.49\\% & 100.48\\%\n",
      "T-1 & 96.53\\% & 96.53\\% & 96.53\\%\n",
      "T-2 & 100.75\\% & 100.75\\% & 100.75\\%\n",
      "T-3 & 99.74\\% & 99.74\\% & 99.74\\%\n",
      "T-4 & 96.72\\% & 96.72\\% & 96.72\\%\n",
      "W-1 & 99.15\\% & 99.15\\% & 99.15\\%\n",
      "W-2 & 98.17\\% & 98.17\\% & 98.17\\%\n",
      "W-3 & 100.47\\% & 100.47\\% & 100.47\\%\n"
     ]
    }
   ],
   "source": [
    "df_latex = df_test_min_max.reset_index()[['case','Min L2 error [%]','Max L2 error [%]','Mean L2 error [%]']]\n",
    "\n",
    "val_idx = [key for key in df_latex.keys() if key != 'case']\n",
    "\n",
    "for idx, row in df_latex.iterrows():\n",
    "    output = row['case']\n",
    "    for val_idx_ in val_idx:\n",
    "#         output += f' & {row[val_idx_][0]:.2f}\\% - {row[val_idx_][1]:.2f}\\%'\n",
    "        output += f' & {row[val_idx_][0]:.2f}\\%'\n",
    "#     output += f' \\\\\\\\'\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-memory",
   "metadata": {},
   "source": [
    "# Sensor type expanded\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "specific-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "interpolation_dirs = [1,2]               # wall sensors\n",
    "interpolation_dirs += [3,4,5,6,7,8,9]    # line sensors\n",
    "interpolation_dirs += [10,11,12,13]      # T sensors\n",
    "interpolation_dirs += [14,15,16]         # patch sensors\n",
    "interpolation_dirs += [17,18,19]         # dense wall, line, patch sensors\n",
    "\n",
    "for interpolation_dir in interpolation_dirs:\n",
    "    \n",
    "    output_filepath = os.path.join(f'sensor_types_expanded_dataset/experiment_{interpolation_dir}', 'output.json')\n",
    "    config_filepath = os.path.join(f'sensor_types_expanded_dataset/experiment_{interpolation_dir}', 'config.json')\n",
    "    df = pd.read_json(output_filepath)\n",
    "    df = df.drop(columns=['counter'])\n",
    "    df = df.T\n",
    "    config_data = json.load(open(config_filepath))\n",
    "    df['experiment_num'] = interpolation_dir\n",
    "    frames.append(df)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "case = ['W-1','W-2','L-1','L-2','L-3','L-4','L-5','L-6','L-7','T-1','T-2','T-3','T-4','P-1','P-2','P-3','W-3','L-8','P-4']\n",
    "df = df.groupby('experiment_num').last().reset_index()\n",
    "df['case']=case\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "center-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Total prediction time [s]</th>\n",
       "      <th>Total prediction samples</th>\n",
       "      <th>Total training time [s]</th>\n",
       "      <th>Total epochs</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>Prediction time per sample [ms]</th>\n",
       "      <th>Time per epoch [s]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W-1</th>\n",
       "      <td>9.295640</td>\n",
       "      <td>53.710098</td>\n",
       "      <td>18.767111</td>\n",
       "      <td>0.379434</td>\n",
       "      <td>533.0</td>\n",
       "      <td>15.698713</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711883</td>\n",
       "      <td>0.436075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-2</th>\n",
       "      <td>7.023242</td>\n",
       "      <td>35.542352</td>\n",
       "      <td>14.729278</td>\n",
       "      <td>0.360497</td>\n",
       "      <td>533.0</td>\n",
       "      <td>27.622972</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.676355</td>\n",
       "      <td>0.406220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>7.580229</td>\n",
       "      <td>29.709521</td>\n",
       "      <td>14.237167</td>\n",
       "      <td>0.376220</td>\n",
       "      <td>533.0</td>\n",
       "      <td>21.066526</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705854</td>\n",
       "      <td>0.429929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>8.406563</td>\n",
       "      <td>33.325297</td>\n",
       "      <td>16.430828</td>\n",
       "      <td>0.370293</td>\n",
       "      <td>533.0</td>\n",
       "      <td>16.498716</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.694733</td>\n",
       "      <td>0.434177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>9.492031</td>\n",
       "      <td>38.728357</td>\n",
       "      <td>20.249042</td>\n",
       "      <td>0.375748</td>\n",
       "      <td>533.0</td>\n",
       "      <td>13.093411</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.704968</td>\n",
       "      <td>0.451497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>10.088408</td>\n",
       "      <td>43.556111</td>\n",
       "      <td>18.884501</td>\n",
       "      <td>0.372426</td>\n",
       "      <td>533.0</td>\n",
       "      <td>21.100734</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.698736</td>\n",
       "      <td>0.422015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-5</th>\n",
       "      <td>8.565749</td>\n",
       "      <td>23.414263</td>\n",
       "      <td>15.038429</td>\n",
       "      <td>0.374197</td>\n",
       "      <td>533.0</td>\n",
       "      <td>21.815416</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.702059</td>\n",
       "      <td>0.427753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-6</th>\n",
       "      <td>8.409666</td>\n",
       "      <td>32.162774</td>\n",
       "      <td>16.841102</td>\n",
       "      <td>0.372120</td>\n",
       "      <td>533.0</td>\n",
       "      <td>16.480662</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.698162</td>\n",
       "      <td>0.433702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-7</th>\n",
       "      <td>10.099475</td>\n",
       "      <td>48.037307</td>\n",
       "      <td>20.212474</td>\n",
       "      <td>0.369165</td>\n",
       "      <td>533.0</td>\n",
       "      <td>24.856845</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.692618</td>\n",
       "      <td>0.414281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1</th>\n",
       "      <td>9.178988</td>\n",
       "      <td>23.407979</td>\n",
       "      <td>14.601250</td>\n",
       "      <td>0.363209</td>\n",
       "      <td>533.0</td>\n",
       "      <td>18.017149</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.681442</td>\n",
       "      <td>0.419003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-2</th>\n",
       "      <td>7.030420</td>\n",
       "      <td>16.172649</td>\n",
       "      <td>10.538585</td>\n",
       "      <td>0.365404</td>\n",
       "      <td>533.0</td>\n",
       "      <td>21.680287</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.685560</td>\n",
       "      <td>0.416929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-3</th>\n",
       "      <td>5.941670</td>\n",
       "      <td>18.969372</td>\n",
       "      <td>12.454611</td>\n",
       "      <td>0.361166</td>\n",
       "      <td>533.0</td>\n",
       "      <td>13.141161</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.677609</td>\n",
       "      <td>0.438039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-4</th>\n",
       "      <td>5.825157</td>\n",
       "      <td>20.080023</td>\n",
       "      <td>11.319910</td>\n",
       "      <td>0.368579</td>\n",
       "      <td>533.0</td>\n",
       "      <td>21.031759</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.691519</td>\n",
       "      <td>0.420635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-1</th>\n",
       "      <td>5.873667</td>\n",
       "      <td>17.549721</td>\n",
       "      <td>9.973839</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>533.0</td>\n",
       "      <td>23.483573</td>\n",
       "      <td>57.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.704691</td>\n",
       "      <td>0.411993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-2</th>\n",
       "      <td>5.744034</td>\n",
       "      <td>17.370344</td>\n",
       "      <td>9.402358</td>\n",
       "      <td>0.364571</td>\n",
       "      <td>533.0</td>\n",
       "      <td>22.332299</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.683998</td>\n",
       "      <td>0.413561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-3</th>\n",
       "      <td>6.626911</td>\n",
       "      <td>15.189520</td>\n",
       "      <td>10.332189</td>\n",
       "      <td>0.358531</td>\n",
       "      <td>533.0</td>\n",
       "      <td>18.792945</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.672666</td>\n",
       "      <td>0.417621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-3</th>\n",
       "      <td>5.111644</td>\n",
       "      <td>18.694855</td>\n",
       "      <td>11.059075</td>\n",
       "      <td>0.360613</td>\n",
       "      <td>533.0</td>\n",
       "      <td>35.802210</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.676572</td>\n",
       "      <td>0.397802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-8</th>\n",
       "      <td>5.899037</td>\n",
       "      <td>19.607450</td>\n",
       "      <td>12.191627</td>\n",
       "      <td>0.372292</td>\n",
       "      <td>533.0</td>\n",
       "      <td>29.264719</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.698484</td>\n",
       "      <td>0.412179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-4</th>\n",
       "      <td>6.439260</td>\n",
       "      <td>22.982625</td>\n",
       "      <td>12.918274</td>\n",
       "      <td>0.363917</td>\n",
       "      <td>533.0</td>\n",
       "      <td>16.158087</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.682770</td>\n",
       "      <td>0.425213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Min L2 error [%]  Max L2 error [%]  Mean L2 error [%]  \\\n",
       "case                                                          \n",
       "W-1           9.295640         53.710098          18.767111   \n",
       "W-2           7.023242         35.542352          14.729278   \n",
       "L-1           7.580229         29.709521          14.237167   \n",
       "L-2           8.406563         33.325297          16.430828   \n",
       "L-3           9.492031         38.728357          20.249042   \n",
       "L-4          10.088408         43.556111          18.884501   \n",
       "L-5           8.565749         23.414263          15.038429   \n",
       "L-6           8.409666         32.162774          16.841102   \n",
       "L-7          10.099475         48.037307          20.212474   \n",
       "T-1           9.178988         23.407979          14.601250   \n",
       "T-2           7.030420         16.172649          10.538585   \n",
       "T-3           5.941670         18.969372          12.454611   \n",
       "T-4           5.825157         20.080023          11.319910   \n",
       "P-1           5.873667         17.549721           9.973839   \n",
       "P-2           5.744034         17.370344           9.402358   \n",
       "P-3           6.626911         15.189520          10.332189   \n",
       "W-3           5.111644         18.694855          11.059075   \n",
       "L-8           5.899037         19.607450          12.191627   \n",
       "P-4           6.439260         22.982625          12.918274   \n",
       "\n",
       "      Total prediction time [s]  Total prediction samples  \\\n",
       "case                                                        \n",
       "W-1                    0.379434                     533.0   \n",
       "W-2                    0.360497                     533.0   \n",
       "L-1                    0.376220                     533.0   \n",
       "L-2                    0.370293                     533.0   \n",
       "L-3                    0.375748                     533.0   \n",
       "L-4                    0.372426                     533.0   \n",
       "L-5                    0.374197                     533.0   \n",
       "L-6                    0.372120                     533.0   \n",
       "L-7                    0.369165                     533.0   \n",
       "T-1                    0.363209                     533.0   \n",
       "T-2                    0.365404                     533.0   \n",
       "T-3                    0.361166                     533.0   \n",
       "T-4                    0.368579                     533.0   \n",
       "P-1                    0.375600                     533.0   \n",
       "P-2                    0.364571                     533.0   \n",
       "P-3                    0.358531                     533.0   \n",
       "W-3                    0.360613                     533.0   \n",
       "L-8                    0.372292                     533.0   \n",
       "P-4                    0.363917                     533.0   \n",
       "\n",
       "      Total training time [s]  Total epochs  experiment_num  \\\n",
       "case                                                          \n",
       "W-1                 15.698713          36.0               1   \n",
       "W-2                 27.622972          68.0               2   \n",
       "L-1                 21.066526          49.0               3   \n",
       "L-2                 16.498716          38.0               4   \n",
       "L-3                 13.093411          29.0               5   \n",
       "L-4                 21.100734          50.0               6   \n",
       "L-5                 21.815416          51.0               7   \n",
       "L-6                 16.480662          38.0               8   \n",
       "L-7                 24.856845          60.0               9   \n",
       "T-1                 18.017149          43.0              10   \n",
       "T-2                 21.680287          52.0              11   \n",
       "T-3                 13.141161          30.0              12   \n",
       "T-4                 21.031759          50.0              13   \n",
       "P-1                 23.483573          57.0              14   \n",
       "P-2                 22.332299          54.0              15   \n",
       "P-3                 18.792945          45.0              16   \n",
       "W-3                 35.802210          90.0              17   \n",
       "L-8                 29.264719          71.0              18   \n",
       "P-4                 16.158087          38.0              19   \n",
       "\n",
       "      Prediction time per sample [ms]  Time per epoch [s]  \n",
       "case                                                       \n",
       "W-1                          0.711883            0.436075  \n",
       "W-2                          0.676355            0.406220  \n",
       "L-1                          0.705854            0.429929  \n",
       "L-2                          0.694733            0.434177  \n",
       "L-3                          0.704968            0.451497  \n",
       "L-4                          0.698736            0.422015  \n",
       "L-5                          0.702059            0.427753  \n",
       "L-6                          0.698162            0.433702  \n",
       "L-7                          0.692618            0.414281  \n",
       "T-1                          0.681442            0.419003  \n",
       "T-2                          0.685560            0.416929  \n",
       "T-3                          0.677609            0.438039  \n",
       "T-4                          0.691519            0.420635  \n",
       "P-1                          0.704691            0.411993  \n",
       "P-2                          0.683998            0.413561  \n",
       "P-3                          0.672666            0.417621  \n",
       "W-3                          0.676572            0.397802  \n",
       "L-8                          0.698484            0.412179  \n",
       "P-4                          0.682770            0.425213  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df[['min_l2_error','max_l2_error','mean_l2_error', 'total_prediction_time', 'total_prediction_samples', 'total_training_time', 'total_epochs', 'experiment_num','case']].set_index(['case'])\n",
    "df_val[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_val['prediction_time_per_sample'] = df_val['total_prediction_time'] / df_val['total_prediction_samples'] * 1000\n",
    "df_val['time_per_epoch'] = df_val['total_training_time'] / df_val['total_epochs']\n",
    "df_val = df_val.fillna('-')\n",
    "\n",
    "df_val = df_val.rename(columns={\n",
    "    'min_l2_error':'Min L2 error [%]',\n",
    "    'max_l2_error':'Max L2 error [%]',\n",
    "    'mean_l2_error':'Mean L2 error [%]',\n",
    "    'total_prediction_time':'Total prediction time [s]',\n",
    "    'total_prediction_samples':'Total prediction samples',\n",
    "    'prediction_time_per_sample':'Prediction time per sample [ms]',\n",
    "    'total_training_time':'Total training time [s]',\n",
    "    'total_epochs':'Total epochs',\n",
    "    'time_per_epoch': 'Time per epoch [s]'\n",
    "})\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "independent-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Min L2 error POD [%]</th>\n",
       "      <th>Max L2 error POD [%]</th>\n",
       "      <th>Mean L2 error POD [%]</th>\n",
       "      <th>experiment_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W-1</th>\n",
       "      <td>9.295640</td>\n",
       "      <td>53.710098</td>\n",
       "      <td>18.767111</td>\n",
       "      <td>44.077035</td>\n",
       "      <td>209.283113</td>\n",
       "      <td>80.401617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-2</th>\n",
       "      <td>7.023242</td>\n",
       "      <td>35.542352</td>\n",
       "      <td>14.729278</td>\n",
       "      <td>40.157972</td>\n",
       "      <td>162.095429</td>\n",
       "      <td>77.679912</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>7.580229</td>\n",
       "      <td>29.709521</td>\n",
       "      <td>14.237167</td>\n",
       "      <td>39.006243</td>\n",
       "      <td>109.278394</td>\n",
       "      <td>67.501590</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>8.406563</td>\n",
       "      <td>33.325297</td>\n",
       "      <td>16.430828</td>\n",
       "      <td>40.699412</td>\n",
       "      <td>213.817942</td>\n",
       "      <td>81.121065</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>9.492031</td>\n",
       "      <td>38.728357</td>\n",
       "      <td>20.249042</td>\n",
       "      <td>42.961021</td>\n",
       "      <td>131.475992</td>\n",
       "      <td>80.055863</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>10.088408</td>\n",
       "      <td>43.556111</td>\n",
       "      <td>18.884501</td>\n",
       "      <td>40.370398</td>\n",
       "      <td>164.447160</td>\n",
       "      <td>76.964361</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-5</th>\n",
       "      <td>8.565749</td>\n",
       "      <td>23.414263</td>\n",
       "      <td>15.038429</td>\n",
       "      <td>54.700460</td>\n",
       "      <td>140.263055</td>\n",
       "      <td>97.615577</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-6</th>\n",
       "      <td>8.409666</td>\n",
       "      <td>32.162774</td>\n",
       "      <td>16.841102</td>\n",
       "      <td>45.738221</td>\n",
       "      <td>171.360662</td>\n",
       "      <td>95.607905</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-7</th>\n",
       "      <td>10.099475</td>\n",
       "      <td>48.037307</td>\n",
       "      <td>20.212474</td>\n",
       "      <td>49.995707</td>\n",
       "      <td>122.718698</td>\n",
       "      <td>96.983133</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1</th>\n",
       "      <td>9.178988</td>\n",
       "      <td>23.407979</td>\n",
       "      <td>14.601250</td>\n",
       "      <td>44.236919</td>\n",
       "      <td>133.912670</td>\n",
       "      <td>87.143259</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-2</th>\n",
       "      <td>7.030420</td>\n",
       "      <td>16.172649</td>\n",
       "      <td>10.538585</td>\n",
       "      <td>36.939487</td>\n",
       "      <td>107.421568</td>\n",
       "      <td>87.039587</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-3</th>\n",
       "      <td>5.941670</td>\n",
       "      <td>18.969372</td>\n",
       "      <td>12.454611</td>\n",
       "      <td>37.986921</td>\n",
       "      <td>123.187459</td>\n",
       "      <td>82.455430</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-4</th>\n",
       "      <td>5.825157</td>\n",
       "      <td>20.080023</td>\n",
       "      <td>11.319910</td>\n",
       "      <td>37.364829</td>\n",
       "      <td>113.052951</td>\n",
       "      <td>72.616618</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-1</th>\n",
       "      <td>5.873667</td>\n",
       "      <td>17.549721</td>\n",
       "      <td>9.973839</td>\n",
       "      <td>30.973169</td>\n",
       "      <td>109.996682</td>\n",
       "      <td>80.167173</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-2</th>\n",
       "      <td>5.744034</td>\n",
       "      <td>17.370344</td>\n",
       "      <td>9.402358</td>\n",
       "      <td>22.986138</td>\n",
       "      <td>82.247618</td>\n",
       "      <td>47.818229</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-3</th>\n",
       "      <td>6.626911</td>\n",
       "      <td>15.189520</td>\n",
       "      <td>10.332189</td>\n",
       "      <td>4.269199</td>\n",
       "      <td>22.817952</td>\n",
       "      <td>11.253410</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-3</th>\n",
       "      <td>5.111644</td>\n",
       "      <td>18.694855</td>\n",
       "      <td>11.059075</td>\n",
       "      <td>34.799467</td>\n",
       "      <td>100.024924</td>\n",
       "      <td>73.015983</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-8</th>\n",
       "      <td>5.899037</td>\n",
       "      <td>19.607450</td>\n",
       "      <td>12.191627</td>\n",
       "      <td>34.656202</td>\n",
       "      <td>101.386871</td>\n",
       "      <td>70.986146</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-4</th>\n",
       "      <td>6.439260</td>\n",
       "      <td>22.982625</td>\n",
       "      <td>12.918274</td>\n",
       "      <td>26.285901</td>\n",
       "      <td>100.538222</td>\n",
       "      <td>60.720276</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Min L2 error [%]  Max L2 error [%]  Mean L2 error [%]  \\\n",
       "case                                                          \n",
       "W-1           9.295640         53.710098          18.767111   \n",
       "W-2           7.023242         35.542352          14.729278   \n",
       "L-1           7.580229         29.709521          14.237167   \n",
       "L-2           8.406563         33.325297          16.430828   \n",
       "L-3           9.492031         38.728357          20.249042   \n",
       "L-4          10.088408         43.556111          18.884501   \n",
       "L-5           8.565749         23.414263          15.038429   \n",
       "L-6           8.409666         32.162774          16.841102   \n",
       "L-7          10.099475         48.037307          20.212474   \n",
       "T-1           9.178988         23.407979          14.601250   \n",
       "T-2           7.030420         16.172649          10.538585   \n",
       "T-3           5.941670         18.969372          12.454611   \n",
       "T-4           5.825157         20.080023          11.319910   \n",
       "P-1           5.873667         17.549721           9.973839   \n",
       "P-2           5.744034         17.370344           9.402358   \n",
       "P-3           6.626911         15.189520          10.332189   \n",
       "W-3           5.111644         18.694855          11.059075   \n",
       "L-8           5.899037         19.607450          12.191627   \n",
       "P-4           6.439260         22.982625          12.918274   \n",
       "\n",
       "      Min L2 error POD [%]  Max L2 error POD [%]  Mean L2 error POD [%]  \\\n",
       "case                                                                      \n",
       "W-1              44.077035            209.283113              80.401617   \n",
       "W-2              40.157972            162.095429              77.679912   \n",
       "L-1              39.006243            109.278394              67.501590   \n",
       "L-2              40.699412            213.817942              81.121065   \n",
       "L-3              42.961021            131.475992              80.055863   \n",
       "L-4              40.370398            164.447160              76.964361   \n",
       "L-5              54.700460            140.263055              97.615577   \n",
       "L-6              45.738221            171.360662              95.607905   \n",
       "L-7              49.995707            122.718698              96.983133   \n",
       "T-1              44.236919            133.912670              87.143259   \n",
       "T-2              36.939487            107.421568              87.039587   \n",
       "T-3              37.986921            123.187459              82.455430   \n",
       "T-4              37.364829            113.052951              72.616618   \n",
       "P-1              30.973169            109.996682              80.167173   \n",
       "P-2              22.986138             82.247618              47.818229   \n",
       "P-3               4.269199             22.817952              11.253410   \n",
       "W-3              34.799467            100.024924              73.015983   \n",
       "L-8              34.656202            101.386871              70.986146   \n",
       "P-4              26.285901            100.538222              60.720276   \n",
       "\n",
       "      experiment_num  \n",
       "case                  \n",
       "W-1                1  \n",
       "W-2                2  \n",
       "L-1                3  \n",
       "L-2                4  \n",
       "L-3                5  \n",
       "L-4                6  \n",
       "L-5                7  \n",
       "L-6                8  \n",
       "L-7                9  \n",
       "T-1               10  \n",
       "T-2               11  \n",
       "T-3               12  \n",
       "T-4               13  \n",
       "P-1               14  \n",
       "P-2               15  \n",
       "P-3               16  \n",
       "W-3               17  \n",
       "L-8               18  \n",
       "P-4               19  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_err = df[['min_l2_error','max_l2_error','mean_l2_error', 'min_l2_error_pod','max_l2_error_pod','mean_l2_error_pod', 'experiment_num','case']].set_index(['case'])\n",
    "df_val_err[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_val_err[['min_l2_error_pod', 'max_l2_error_pod', 'mean_l2_error_pod']] *= 100\n",
    "df_val_err = df_val_err.fillna('-')\n",
    "\n",
    "df_val_err = df_val_err.rename(columns={\n",
    "    'min_l2_error':'Min L2 error [%]',\n",
    "    'max_l2_error':'Max L2 error [%]',\n",
    "    'mean_l2_error':'Mean L2 error [%]',\n",
    "    'min_l2_error_pod':'Min L2 error POD [%]',\n",
    "    'max_l2_error_pod':'Max L2 error POD [%]',\n",
    "    'mean_l2_error_pod':'Mean L2 error POD [%]',\n",
    "})\n",
    "df_val_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "talented-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-1 & 9.30\\% & 53.71\\% & 18.77\\% & 40.08\\% & 172.34\\% & 90.06\\% & 99.40\\% & 99.40\\% & 99.40\\%\\\\\n",
      "W-2 & 7.02\\% & 35.54\\% & 14.73\\% & 42.36\\% & 175.98\\% & 98.49\\% & 101.33\\% & 101.33\\% & 101.33\\%\\\\\n",
      "L-1 & 7.58\\% & 29.71\\% & 14.24\\% & 44.81\\% & 101.02\\% & 73.08\\% & 99.61\\% & 99.61\\% & 99.61\\%\\\\\n",
      "L-2 & 8.41\\% & 33.33\\% & 16.43\\% & 44.78\\% & 164.54\\% & 91.84\\% & 92.35\\% & 92.35\\% & 92.35\\%\\\\\n",
      "L-3 & 9.49\\% & 38.73\\% & 20.25\\% & 22.79\\% & 62.85\\% & 39.14\\% & 105.74\\% & 105.74\\% & 105.74\\%\\\\\n",
      "L-4 & 10.09\\% & 43.56\\% & 18.88\\% & 48.43\\% & 180.90\\% & 84.71\\% & 102.42\\% & 102.42\\% & 102.42\\%\\\\\n",
      "L-5 & 8.57\\% & 23.41\\% & 15.04\\% & 24.26\\% & 65.42\\% & 39.56\\% & 108.10\\% & 108.10\\% & 108.10\\%\\\\\n",
      "L-6 & 8.41\\% & 32.16\\% & 16.84\\% & 26.44\\% & 85.75\\% & 46.74\\% & 99.45\\% & 99.45\\% & 99.45\\%\\\\\n",
      "L-7 & 10.10\\% & 48.04\\% & 20.21\\% & 27.40\\% & 82.46\\% & 43.26\\% & 105.47\\% & 105.47\\% & 105.47\\%\\\\\n",
      "T-1 & 9.18\\% & 23.41\\% & 14.60\\% & 31.80\\% & 66.66\\% & 47.73\\% & 94.75\\% & 94.75\\% & 94.75\\%\\\\\n",
      "T-2 & 7.03\\% & 16.17\\% & 10.54\\% & 29.78\\% & 64.10\\% & 45.29\\% & 95.36\\% & 95.36\\% & 95.36\\%\\\\\n",
      "T-3 & 5.94\\% & 18.97\\% & 12.45\\% & 32.30\\% & 63.25\\% & 42.78\\% & 98.00\\% & 98.00\\% & 98.00\\%\\\\\n",
      "T-4 & 5.83\\% & 20.08\\% & 11.32\\% & 28.73\\% & 76.79\\% & 49.08\\% & 96.50\\% & 96.50\\% & 96.50\\%\\\\\n",
      "P-1 & 5.87\\% & 17.55\\% & 9.97\\% & 29.92\\% & 54.24\\% & 40.16\\% & 86.03\\% & 86.03\\% & 86.03\\%\\\\\n",
      "P-2 & 5.74\\% & 17.37\\% & 9.40\\% & 31.67\\% & 77.69\\% & 47.34\\% & 103.36\\% & 103.36\\% & 103.36\\%\\\\\n",
      "P-3 & 6.63\\% & 15.19\\% & 10.33\\% & 27.17\\% & 44.60\\% & 35.01\\% & 94.34\\% & 94.34\\% & 94.34\\%\\\\\n",
      "W-3 & 5.11\\% & 18.69\\% & 11.06\\% & 59.15\\% & 112.02\\% & 90.54\\% & 102.01\\% & 102.01\\% & 102.01\\%\\\\\n",
      "L-8 & 5.90\\% & 19.61\\% & 12.19\\% & 42.79\\% & 83.21\\% & 64.00\\% & 106.53\\% & 106.54\\% & 106.53\\%\\\\\n",
      "P-4 & 6.44\\% & 22.98\\% & 12.92\\% & 27.79\\% & 62.86\\% & 41.16\\% & 87.17\\% & 87.17\\% & 87.17\\%\\\\\n"
     ]
    }
   ],
   "source": [
    "# df_latex = df[['case','min_l2_error','max_l2_error','mean_l2_error', 'min_l2_error_pod','max_l2_error_pod','mean_l2_error_pod','total_training_time','total_epochs']]\n",
    "df_latex = df[['case','min_l2_error','max_l2_error','mean_l2_error','cylinder_half_min_l2_error','cylinder_half_max_l2_error','cylinder_half_mean_l2_error', 'diamond_ar_2p0_min_l2_error','diamond_ar_2p0_max_l2_error','diamond_ar_2p0_mean_l2_error',]]\n",
    "df_latex[['min_l2_error', 'max_l2_error', 'mean_l2_error']] *= 100\n",
    "df_latex[['cylinder_half_min_l2_error', 'cylinder_half_max_l2_error', 'cylinder_half_mean_l2_error']] *= 100\n",
    "df_latex[['diamond_ar_2p0_min_l2_error', 'diamond_ar_2p0_max_l2_error', 'diamond_ar_2p0_mean_l2_error']] *= 100\n",
    "\n",
    "val_idx = [key for key in df_latex.columns if key != 'case']\n",
    "for idx, row in df_latex.iterrows():\n",
    "    output = row['case']\n",
    "    for val_idx_ in val_idx:\n",
    "        if val_idx_ != 'total_training_time':\n",
    "            output += f' & {row[val_idx_]:.2f}\\%'\n",
    "        else:\n",
    "            output += f' & {row[val_idx_]:.2f}'\n",
    "    output += f'\\\\\\\\'\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "focal-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min L2 error [%]</th>\n",
       "      <th>Max L2 error [%]</th>\n",
       "      <th>Mean L2 error [%]</th>\n",
       "      <th>Total prediction time [s]</th>\n",
       "      <th>Total prediction samples</th>\n",
       "      <th>experiment_num</th>\n",
       "      <th>Prediction time per sample [ms]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L-1</th>\n",
       "      <td>[99.61, 99.61]</td>\n",
       "      <td>[99.61, 99.61]</td>\n",
       "      <td>[99.61, 99.61]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-2</th>\n",
       "      <td>[92.35, 92.35]</td>\n",
       "      <td>[92.35, 92.35]</td>\n",
       "      <td>[92.35, 92.35]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-3</th>\n",
       "      <td>[105.74, 105.74]</td>\n",
       "      <td>[105.74, 105.74]</td>\n",
       "      <td>[105.74, 105.74]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-4</th>\n",
       "      <td>[102.42, 102.42]</td>\n",
       "      <td>[102.42, 102.42]</td>\n",
       "      <td>[102.42, 102.42]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-5</th>\n",
       "      <td>[108.1, 108.1]</td>\n",
       "      <td>[108.1, 108.1]</td>\n",
       "      <td>[108.1, 108.1]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[7, 7]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-6</th>\n",
       "      <td>[99.45, 99.45]</td>\n",
       "      <td>[99.45, 99.45]</td>\n",
       "      <td>[99.45, 99.45]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-7</th>\n",
       "      <td>[105.47, 105.47]</td>\n",
       "      <td>[105.47, 105.47]</td>\n",
       "      <td>[105.47, 105.47]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[9, 9]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-8</th>\n",
       "      <td>[106.53, 106.53]</td>\n",
       "      <td>[106.54, 106.54]</td>\n",
       "      <td>[106.53, 106.53]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[18, 18]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-1</th>\n",
       "      <td>[86.03, 86.03]</td>\n",
       "      <td>[86.03, 86.03]</td>\n",
       "      <td>[86.03, 86.03]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[14, 14]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-2</th>\n",
       "      <td>[103.36, 103.36]</td>\n",
       "      <td>[103.36, 103.36]</td>\n",
       "      <td>[103.36, 103.36]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[15, 15]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-3</th>\n",
       "      <td>[94.34, 94.34]</td>\n",
       "      <td>[94.34, 94.34]</td>\n",
       "      <td>[94.34, 94.34]</td>\n",
       "      <td>[0.23, 0.23]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[16, 16]</td>\n",
       "      <td>[0.57, 0.57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-4</th>\n",
       "      <td>[87.17, 87.17]</td>\n",
       "      <td>[87.17, 87.17]</td>\n",
       "      <td>[87.17, 87.17]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[19, 19]</td>\n",
       "      <td>[0.55, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1</th>\n",
       "      <td>[94.75, 94.75]</td>\n",
       "      <td>[94.75, 94.75]</td>\n",
       "      <td>[94.75, 94.75]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-2</th>\n",
       "      <td>[95.36, 95.36]</td>\n",
       "      <td>[95.36, 95.36]</td>\n",
       "      <td>[95.36, 95.36]</td>\n",
       "      <td>[0.21, 0.21]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-3</th>\n",
       "      <td>[98.0, 98.0]</td>\n",
       "      <td>[98.0, 98.0]</td>\n",
       "      <td>[98.0, 98.0]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[12, 12]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-4</th>\n",
       "      <td>[96.5, 96.5]</td>\n",
       "      <td>[96.5, 96.5]</td>\n",
       "      <td>[96.5, 96.5]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[13, 13]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-1</th>\n",
       "      <td>[99.4, 99.4]</td>\n",
       "      <td>[99.4, 99.4]</td>\n",
       "      <td>[99.4, 99.4]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-2</th>\n",
       "      <td>[101.33, 101.33]</td>\n",
       "      <td>[101.33, 101.33]</td>\n",
       "      <td>[101.33, 101.33]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-3</th>\n",
       "      <td>[102.01, 102.01]</td>\n",
       "      <td>[102.01, 102.01]</td>\n",
       "      <td>[102.01, 102.01]</td>\n",
       "      <td>[0.22, 0.22]</td>\n",
       "      <td>[400.0, 400.0]</td>\n",
       "      <td>[17, 17]</td>\n",
       "      <td>[0.54, 0.54]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Min L2 error [%]  Max L2 error [%] Mean L2 error [%]  \\\n",
       "case                                                         \n",
       "L-1     [99.61, 99.61]    [99.61, 99.61]    [99.61, 99.61]   \n",
       "L-2     [92.35, 92.35]    [92.35, 92.35]    [92.35, 92.35]   \n",
       "L-3   [105.74, 105.74]  [105.74, 105.74]  [105.74, 105.74]   \n",
       "L-4   [102.42, 102.42]  [102.42, 102.42]  [102.42, 102.42]   \n",
       "L-5     [108.1, 108.1]    [108.1, 108.1]    [108.1, 108.1]   \n",
       "L-6     [99.45, 99.45]    [99.45, 99.45]    [99.45, 99.45]   \n",
       "L-7   [105.47, 105.47]  [105.47, 105.47]  [105.47, 105.47]   \n",
       "L-8   [106.53, 106.53]  [106.54, 106.54]  [106.53, 106.53]   \n",
       "P-1     [86.03, 86.03]    [86.03, 86.03]    [86.03, 86.03]   \n",
       "P-2   [103.36, 103.36]  [103.36, 103.36]  [103.36, 103.36]   \n",
       "P-3     [94.34, 94.34]    [94.34, 94.34]    [94.34, 94.34]   \n",
       "P-4     [87.17, 87.17]    [87.17, 87.17]    [87.17, 87.17]   \n",
       "T-1     [94.75, 94.75]    [94.75, 94.75]    [94.75, 94.75]   \n",
       "T-2     [95.36, 95.36]    [95.36, 95.36]    [95.36, 95.36]   \n",
       "T-3       [98.0, 98.0]      [98.0, 98.0]      [98.0, 98.0]   \n",
       "T-4       [96.5, 96.5]      [96.5, 96.5]      [96.5, 96.5]   \n",
       "W-1       [99.4, 99.4]      [99.4, 99.4]      [99.4, 99.4]   \n",
       "W-2   [101.33, 101.33]  [101.33, 101.33]  [101.33, 101.33]   \n",
       "W-3   [102.01, 102.01]  [102.01, 102.01]  [102.01, 102.01]   \n",
       "\n",
       "     Total prediction time [s] Total prediction samples experiment_num  \\\n",
       "case                                                                     \n",
       "L-1               [0.21, 0.21]           [400.0, 400.0]         [3, 3]   \n",
       "L-2               [0.22, 0.22]           [400.0, 400.0]         [4, 4]   \n",
       "L-3               [0.22, 0.22]           [400.0, 400.0]         [5, 5]   \n",
       "L-4               [0.22, 0.22]           [400.0, 400.0]         [6, 6]   \n",
       "L-5               [0.22, 0.22]           [400.0, 400.0]         [7, 7]   \n",
       "L-6               [0.22, 0.22]           [400.0, 400.0]         [8, 8]   \n",
       "L-7               [0.22, 0.22]           [400.0, 400.0]         [9, 9]   \n",
       "L-8               [0.22, 0.22]           [400.0, 400.0]       [18, 18]   \n",
       "P-1               [0.22, 0.22]           [400.0, 400.0]       [14, 14]   \n",
       "P-2               [0.22, 0.22]           [400.0, 400.0]       [15, 15]   \n",
       "P-3               [0.23, 0.23]           [400.0, 400.0]       [16, 16]   \n",
       "P-4               [0.22, 0.22]           [400.0, 400.0]       [19, 19]   \n",
       "T-1               [0.22, 0.22]           [400.0, 400.0]       [10, 10]   \n",
       "T-2               [0.21, 0.21]           [400.0, 400.0]       [11, 11]   \n",
       "T-3               [0.22, 0.22]           [400.0, 400.0]       [12, 12]   \n",
       "T-4               [0.22, 0.22]           [400.0, 400.0]       [13, 13]   \n",
       "W-1               [0.22, 0.22]           [400.0, 400.0]         [1, 1]   \n",
       "W-2               [0.22, 0.22]           [400.0, 400.0]         [2, 2]   \n",
       "W-3               [0.22, 0.22]           [400.0, 400.0]       [17, 17]   \n",
       "\n",
       "     Prediction time per sample [ms]  \n",
       "case                                  \n",
       "L-1                     [0.54, 0.54]  \n",
       "L-2                     [0.55, 0.55]  \n",
       "L-3                     [0.54, 0.54]  \n",
       "L-4                     [0.54, 0.54]  \n",
       "L-5                     [0.55, 0.55]  \n",
       "L-6                     [0.54, 0.54]  \n",
       "L-7                     [0.55, 0.55]  \n",
       "L-8                     [0.55, 0.55]  \n",
       "P-1                     [0.55, 0.55]  \n",
       "P-2                     [0.54, 0.54]  \n",
       "P-3                     [0.57, 0.57]  \n",
       "P-4                     [0.55, 0.55]  \n",
       "T-1                     [0.54, 0.54]  \n",
       "T-2                     [0.54, 0.54]  \n",
       "T-3                     [0.54, 0.54]  \n",
       "T-4                     [0.54, 0.54]  \n",
       "W-1                     [0.54, 0.54]  \n",
       "W-2                     [0.54, 0.54]  \n",
       "W-3                     [0.54, 0.54]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obstacles = [\"diamond_ar_1p25\",\n",
    "             \"diamond_ar_1p5\",\n",
    "             \"diamond_ar_1p66\",\n",
    "             \"diamond_ar_2p0\",\n",
    "             \"triangle_ar_1p25\",\n",
    "             \"triangle_ar_1p5\",\n",
    "             \"triangle_ar_1p66\",\n",
    "             \"triangle_ar_2p0\",\n",
    "             \"cylinder_half\",\n",
    "             \"cylinder_half_flipped\"]\n",
    "\n",
    "obstacles = [\"diamond_ar_2p0\"]\n",
    "\n",
    "frames_test = []\n",
    "for obstacle in obstacles:\n",
    "    df_test = df[[f'{obstacle}_min_l2_error',f'{obstacle}_max_l2_error',f'{obstacle}_mean_l2_error',f'{obstacle}_total_prediction_time',f'{obstacle}_total_prediction_samples','experiment_num','case']].set_index(['case'])\n",
    "    df_test[[f'{obstacle}_min_l2_error',f'{obstacle}_max_l2_error',f'{obstacle}_mean_l2_error']] *= 100\n",
    "    df_test[f'{obstacle}_prediction_time_per_sample'] = df_test[f'{obstacle}_total_prediction_time'] / df_test[f'{obstacle}_total_prediction_samples'] * 1000\n",
    "    df_test = df_test.fillna('-')\n",
    "\n",
    "    df_test = df_test.rename(columns={\n",
    "        f'{obstacle}_min_l2_error':'Min L2 error [%]',\n",
    "        f'{obstacle}_max_l2_error':'Max L2 error [%]',\n",
    "        f'{obstacle}_mean_l2_error':'Mean L2 error [%]',\n",
    "        f'{obstacle}_total_prediction_time':'Total prediction time [s]',\n",
    "        f'{obstacle}_total_prediction_samples':'Total prediction samples',\n",
    "        f'{obstacle}_prediction_time_per_sample':'Prediction time per sample [ms]',\n",
    "    })\n",
    "    frames_test.append(df_test)\n",
    "\n",
    "df_test = pd.concat(frames_test)\n",
    "df_test_max = df_test.groupby(level=[0]).max()\n",
    "df_test_min = df_test.groupby(level=[0]).min()\n",
    "\n",
    "df_test_min_max = df_test_min.applymap(lambda x : [round(x,2)]) + df_test_max.applymap(lambda x : [round(x,2)])\n",
    "\n",
    "df_test_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "assured-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-1 & 99.61\\% & 99.61\\% & 99.61\\%\n",
      "L-2 & 92.35\\% & 92.35\\% & 92.35\\%\n",
      "L-3 & 105.74\\% & 105.74\\% & 105.74\\%\n",
      "L-4 & 102.42\\% & 102.42\\% & 102.42\\%\n",
      "L-5 & 108.10\\% & 108.10\\% & 108.10\\%\n",
      "L-6 & 99.45\\% & 99.45\\% & 99.45\\%\n",
      "L-7 & 105.47\\% & 105.47\\% & 105.47\\%\n",
      "L-8 & 106.53\\% & 106.54\\% & 106.53\\%\n",
      "P-1 & 86.03\\% & 86.03\\% & 86.03\\%\n",
      "P-2 & 103.36\\% & 103.36\\% & 103.36\\%\n",
      "P-3 & 94.34\\% & 94.34\\% & 94.34\\%\n",
      "P-4 & 87.17\\% & 87.17\\% & 87.17\\%\n",
      "T-1 & 94.75\\% & 94.75\\% & 94.75\\%\n",
      "T-2 & 95.36\\% & 95.36\\% & 95.36\\%\n",
      "T-3 & 98.00\\% & 98.00\\% & 98.00\\%\n",
      "T-4 & 96.50\\% & 96.50\\% & 96.50\\%\n",
      "W-1 & 99.40\\% & 99.40\\% & 99.40\\%\n",
      "W-2 & 101.33\\% & 101.33\\% & 101.33\\%\n",
      "W-3 & 102.01\\% & 102.01\\% & 102.01\\%\n"
     ]
    }
   ],
   "source": [
    "df_latex = df_test_min_max.reset_index()[['case','Min L2 error [%]','Max L2 error [%]','Mean L2 error [%]']]\n",
    "\n",
    "val_idx = [key for key in df_latex.keys() if key != 'case']\n",
    "\n",
    "for idx, row in df_latex.iterrows():\n",
    "    output = row['case']\n",
    "    for val_idx_ in val_idx:\n",
    "#         output += f' & {row[val_idx_][0]:.2f}\\% - {row[val_idx_][1]:.2f}\\%'\n",
    "        output += f' & {row[val_idx_][0]:.2f}\\%'\n",
    "#     output += f' \\\\\\\\'\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-pierre",
   "metadata": {},
   "source": [
    "# CNN equivalent sensor placement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alive-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from utils import *\n",
    "import json\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "similar-prior",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 256\n",
      "        Spanwise:\n",
      "            Total line length: 2.56 unit lengths\n",
      "            Sensor separation: 0.16 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.56 unit lengths\n",
      "            Sensor separation: 0.16 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -32.3940, max: 32.4120, mean: -0.0003\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "37.19\\% & 42.22\\% & 39.71\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -26.9140, max: 26.4560, mean: -0.0001\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "53.94\\% & 62.96\\% & 58.10\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -24.0870, max: 24.1830, mean: -0.0001\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "71.04\\% & 75.20\\% & 73.13\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "84.04\\% & 84.04\\% & 84.04\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -21.0650, max: 21.2150, mean: -0.0001\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "55.77\\% & 67.04\\% & 61.01\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -22.6170, max: 22.4370, mean: -0.0001\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "70.15\\% & 82.38\\% & 75.47\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -21.9990, max: 21.9900, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.06\\% & 88.40\\% & 83.85\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -22.3750, max: 22.7460, mean: -0.0001\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "94.60\\% & 94.66\\% & 94.63\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -51.9737, max: 52.0541, mean: -0.0004\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "35.43\\% & 48.28\\% & 41.57\\%\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -7.4595, max: 7.4917, mean: -0.0003\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 1, 40)             10280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 1, 40)             160       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1, 45)             1845      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 1, 45)             180       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1, 100000)         4600000   \n",
      "=================================================================\n",
      "Total params: 4,612,465\n",
      "Trainable params: 4,612,295\n",
      "Non-trainable params: 170\n",
      "_________________________________________________________________\n",
      "49.08\\% & 59.15\\% & 54.42\\%\n"
     ]
    }
   ],
   "source": [
    "save_folder_path = 'sensor_types/experiment_16'\n",
    "\n",
    "config_json = os.path.join(save_folder_path, 'config.json')\n",
    "config = json.load(open(config_json))\n",
    "sensor_params = config['sensor_parameters']\n",
    "scaling_params = config['data_scaling_parameters']\n",
    "split_ratio = config['training_parameters']['split_ratio']\n",
    "\n",
    "filename = '../data/primitives/cylinder/w_z.npy'\n",
    "y = np.load(filename)\n",
    "y = y[100:,:,:]\n",
    "y = np.transpose(y, (0, 2, 1))\n",
    "y_train, y_test, m, n = split_data(y, split_ratio)\n",
    "y_train_scaled, y_test_scaled, scaling_params = rescale_data(y_train, y_test, scaling_params=scaling_params)\n",
    "y_train_reshaped = reshape_for_ann(y_train_scaled)\n",
    "y_test_reshaped = reshape_for_ann(y_test_scaled)\n",
    "\n",
    "sensor_params['m'] = m\n",
    "sensor_params['n'] = n\n",
    "\n",
    "sensors, sensor_params = get_sensor_data(y_train_reshaped, sensor_params)\n",
    "sensors_test, _ = get_sensor_data(y_test_reshaped, sensor_params)\n",
    "\n",
    "sensors = reshape_for_ann(sensors)\n",
    "sensors_test = reshape_for_ann(sensors_test)\n",
    "\n",
    "obstacles = [\"diamond_ar_1p25\",\n",
    "             \"diamond_ar_1p5\",\n",
    "             \"diamond_ar_1p66\",\n",
    "             \"diamond_ar_2p0\",\n",
    "             \"triangle_ar_1p25\",\n",
    "             \"triangle_ar_1p5\",\n",
    "             \"triangle_ar_1p66\",\n",
    "             \"triangle_ar_2p0\",\n",
    "             \"cylinder_half\",\n",
    "             \"cylinder_half_flipped\"]\n",
    "\n",
    "mins = []\n",
    "maxs = []\n",
    "means = []\n",
    "for obstacle in obstacles:\n",
    "    unseen_filename = f'../data/primitives/{obstacle}/w_z.npy'\n",
    "    unseen_y = np.load(unseen_filename)\n",
    "    unseen_y = unseen_y[100:,:,:]\n",
    "    unseen_y = np.transpose(unseen_y, (0, 2, 1))\n",
    "\n",
    "    unseen_y_scaled, _, _ = rescale_data(unseen_y, None, scaling_params=scaling_params)\n",
    "    unseen_y_reshaped = reshape_for_ann(unseen_y_scaled)\n",
    "    unseen_sensors, _ = get_sensor_data(unseen_y_reshaped, sensor_params)\n",
    "    unseen_sensors = reshape_for_ann(unseen_sensors)\n",
    "\n",
    "    with tf.device('cpu:0'):\n",
    "        model_path = f'{save_folder_path}/model.h5'\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        model.summary()\n",
    "        prediction = model.predict(unseen_sensors)\n",
    "    #     prediction = model.predict(sensors_test)\n",
    "\n",
    "    prediction = prediction.reshape(prediction.shape[0],m,n)\n",
    "    prediction_inv_scaled = unscale_data(prediction, scaling_params)\n",
    "    \n",
    "    upstream_mask = sensor_params.get('upstream_mask')\n",
    "\n",
    "    line_start_streamwise = sensor_params['line_start_streamwise']\n",
    "    line_end_streamwise = sensor_params['line_end_streamwise']\n",
    "    line_start_spanwise = sensor_params['line_start_spanwise']\n",
    "    line_end_spanwise = sensor_params['line_end_spanwise']\n",
    "\n",
    "    upstream_mask[line_end_streamwise+1:, :] = 0\n",
    "    upstream_mask[:, :line_start_spanwise] = 0\n",
    "    upstream_mask[:, line_end_spanwise+1:] = 0\n",
    "\n",
    "    # img_per_pixel_abs_error = np.abs(prediction_inv_scaled - y_test) * upstream_mask\n",
    "    # img_overall_l2_error = calculate_l2_error_norm(prediction_inv_scaled * upstream_mask, y_test * upstream_mask)\n",
    "    img_per_pixel_abs_error = np.abs(prediction_inv_scaled - unseen_y) * upstream_mask\n",
    "    img_overall_l2_error = calculate_l2_error_norm(prediction_inv_scaled * upstream_mask, unseen_y * upstream_mask)\n",
    "\n",
    "    mins.append(img_overall_l2_error.min())\n",
    "    maxs.append(img_overall_l2_error.max())\n",
    "    means.append(img_overall_l2_error.mean())\n",
    "\n",
    "    print(f'{img_overall_l2_error.min()*100:.2f}\\% & {img_overall_l2_error.max()*100:.2f}\\% & {img_overall_l2_error.mean()*100:.2f}\\%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "uniform-mason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.43\\% - 94.60\\% & 42.22\\% - 94.66\\% & 39.71\\% - 94.63\\% & \n"
     ]
    }
   ],
   "source": [
    "print(f'{min(mins)*100:.2f}\\% - {max(mins)*100:.2f}\\% & {min(maxs)*100:.2f}\\% - {max(maxs)*100:.2f}\\% & {min(means)*100:.2f}\\% - {max(means)*100:.2f}\\% & ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "formal-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.08\\% & 59.15\\% & 54.42\\%\n"
     ]
    }
   ],
   "source": [
    "upstream_mask = sensor_params.get('upstream_mask')\n",
    "\n",
    "line_start_streamwise = sensor_params['line_start_streamwise']\n",
    "line_end_streamwise = sensor_params['line_end_streamwise']\n",
    "line_start_spanwise = sensor_params['line_start_spanwise']\n",
    "line_end_spanwise = sensor_params['line_end_spanwise']\n",
    "\n",
    "upstream_mask[line_end_streamwise+1:, :] = 0\n",
    "upstream_mask[:, :line_start_spanwise] = 0\n",
    "upstream_mask[:, line_end_spanwise+1:] = 0\n",
    "\n",
    "# img_per_pixel_abs_error = np.abs(prediction_inv_scaled - y_test) * upstream_mask\n",
    "# img_overall_l2_error = calculate_l2_error_norm(prediction_inv_scaled * upstream_mask, y_test * upstream_mask)\n",
    "img_per_pixel_abs_error = np.abs(prediction_inv_scaled - unseen_y) * upstream_mask\n",
    "img_overall_l2_error = calculate_l2_error_norm(prediction_inv_scaled * upstream_mask, unseen_y * upstream_mask)\n",
    "\n",
    "\n",
    "\n",
    "print(f'{img_overall_l2_error.min()*100:.2f}\\% & {img_overall_l2_error.max()*100:.2f}\\% & {img_overall_l2_error.mean()*100:.2f}\\%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "authorized-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = error_sample.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eastern-governor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 568.8x1116 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_error_sample = np.argmax(img_overall_l2_error)\n",
    "\n",
    "actual_sample = unseen_y[max_error_sample,:,:]\n",
    "prediction_sample = prediction_inv_scaled[max_error_sample,:,:]\n",
    "error_sample = img_per_pixel_abs_error[max_error_sample, :, :]\n",
    "l2_error_sample = img_overall_l2_error[max_error_sample,0]\n",
    "\n",
    "ygrid = range(n)\n",
    "xgrid = range(m)\n",
    "yv, xv = np.meshgrid(ygrid, xgrid)\n",
    "\n",
    "sensor_locations = sensor_params['pivots']\n",
    "\n",
    "x_sensors = xv.reshape(1, m*n)[:, sensor_locations]\n",
    "y_sensors = yv.reshape(1, m*n)[:, sensor_locations]\n",
    "\n",
    "_, m, n = y_test.shape\n",
    "\n",
    "x = np.arange(0, m, 1)\n",
    "y = np.arange(0, n, 1)\n",
    "mX, mY = np.meshgrid(x, y)\n",
    "minmax = np.nanmax(np.abs(actual_sample)) * 0.65\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(3, facecolor=\"white\",  edgecolor='k', figsize=(7.9,15.5))\n",
    "# fig.suptitle('Output comparison')\n",
    "\n",
    "axs[0].imshow(actual_sample.T, cmap=cmocean.cm.balance, interpolation='none', vmin=-minmax, vmax=minmax)\n",
    "axs[0].contourf(mX, mY, actual_sample.T, 80, cmap=cmocean.cm.balance, alpha=1, vmin=-minmax, vmax=minmax)\n",
    "axs[0].scatter(x_sensors, y_sensors, marker='.', color='#ff7f00', s=100, zorder=5)\n",
    "axs[0].set_title('Actual')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(prediction_sample.T, cmap=cmocean.cm.balance, interpolation='none', vmin=-minmax, vmax=minmax)\n",
    "axs[1].contourf(mX, mY, prediction_sample.T, 80, cmap=cmocean.cm.balance, alpha=1, vmin=-minmax, vmax=minmax)\n",
    "axs[1].scatter(x_sensors, y_sensors, marker='.', color='#ff7f00', s=100, zorder=5)\n",
    "axs[1].set_title('Predicted')          \n",
    "axs[1].axis('off')\n",
    "\n",
    "im2 = axs[2].imshow(error_sample.T, cmap='gray_r', interpolation='none', vmin=0, vmax=max_val)\n",
    "axs[2].set_title(f'Absolute difference. Overall L2 error = {l2_error_sample*100:.4f}%')\n",
    "axs[2].axis('off')\n",
    "axs[2].scatter(x_sensors, y_sensors, marker='.', color='#ff7f00', s=100, zorder=5)\n",
    "fig.colorbar(im2, ax=axs[2], orientation='horizontal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "enabling-pendant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total line length: 2.0 unit lengths\n",
      "        Sensor separation: 0.5 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.5 unit lengths\n",
      "        Total line length: 2.0 unit lengths\n",
      "        Sensor separation: 0.5 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.5 unit lengths\n",
      "        Total line length: 0.8 unit lengths\n",
      "        Sensor separation: 0.2 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.5 unit lengths\n",
      "        Total line length: 2.8 unit lengths\n",
      "        Sensor separation: 0.7 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total line length: 2.0 unit lengths\n",
      "        Sensor separation: 0.5 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total line length: 1.4 unit lengths\n",
      "        Sensor separation: 0.34 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total line length: 2.6 unit lengths\n",
      "        Sensor separation: 0.64 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 5\n",
      "        Spanwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 1.0 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 1.0 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 5)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 9\n",
      "        Spanwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 0.5 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 0.5 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 9)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 7\n",
      "        Spanwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 1.0 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 0.5 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 7)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 7\n",
      "        Spanwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 0.5 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 1.0 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 7)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 9\n",
      "        Spanwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 1.0 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 1.0 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 9)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 16\n",
      "        Spanwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 0.66 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.0 unit lengths\n",
      "            Sensor separation: 0.66 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 16)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 256\n",
      "        Spanwise:\n",
      "            Total line length: 2.56 unit lengths\n",
      "            Sensor separation: 0.16 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 2.56 unit lengths\n",
      "            Sensor separation: 0.16 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 256)\n",
      "Output shape (266, 100000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 15)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.5 unit lengths\n",
      "        Total line length: 3.98 unit lengths\n",
      "        Sensor separation: 0.28 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 15)\n",
      "Output shape (266, 100000)\n",
      "Split data details:\n",
      "    train_data has 266 examples\n",
      "    test_data has 134 examples\n",
      "\n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -5.4248, max: 5.4737, mean: -0.0000\n",
      "    test_data_rescaled has min: -5.4248, max: 5.4741, mean: -0.0007\n",
      "\n",
      "Physically:\n",
      "        Distance from obstacle rear: 0.1 unit lengths\n",
      "        Total sensor count: 15\n",
      "        Spanwise:\n",
      "            Total line length: 3.98 unit lengths\n",
      "            Sensor separation: 1.98 unit lengths\n",
      "        Streamwise:\n",
      "            Total line length: 8.38 unit lengths\n",
      "            Sensor separation: 2.08 unit lengths\n",
      "        \n",
      "Scaled data details:\n",
      "    train_data_rescaled has min: -35.8510, max: 36.6740, mean: -0.0002\n",
      "    test_data_rescaled has min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "\n",
      "Model: POD\n",
      "_________________________________________________________________\n",
      "Steps            Explanation\n",
      "=================================================================\n",
      "SVD              POD decomposition is carried out via singular\n",
      "                 value decomposition (SVD) - np.linalg.svd(y,0)\n",
      "_________________________________________________________________\n",
      "linear_coeff     Solution to the least square problem between\n",
      "                 actual sensors and decomposed sensors with the\n",
      "                 minimum L2 norm is solved via the Moore-Penrose\n",
      "                 pseudo-inverse\n",
      "_________________________________________________________________\n",
      "Prediction       Linear combination of reduced POD modes with\n",
      "                 previously calculated linear coefficients\n",
      "=================================================================\n",
      "Access modes: POD.v\n",
      "Access singular value: POD.s\n",
      "POD plus - True\n",
      "\n",
      "Input shape (266, 15)\n",
      "Output shape (266, 100000)\n"
     ]
    }
   ],
   "source": [
    "mins = []\n",
    "maxs = []\n",
    "means = []\n",
    "for i in range(1,20):\n",
    "    save_folder_path = f'sensor_types/experiment_{i}'\n",
    "\n",
    "    config_json = os.path.join(save_folder_path, 'config.json')\n",
    "    config = json.load(open(config_json))\n",
    "    sensor_params = config['sensor_parameters']\n",
    "    scaling_params = config['data_scaling_parameters']\n",
    "    split_ratio = config['training_parameters']['split_ratio']\n",
    "\n",
    "    filename = '../data/primitives/cylinder/w_z.npy'\n",
    "    y = np.load(filename)\n",
    "    y = y[100:,:,:]\n",
    "    y = np.transpose(y, (0, 2, 1))\n",
    "    y_train, y_test, m, n = split_data(y, split_ratio)\n",
    "    y_train_scaled, y_test_scaled, scaling_params = rescale_data(y_train, y_test, scaling_params=scaling_params)\n",
    "    y_train_reshaped = reshape_for_ann(y_train_scaled)\n",
    "    y_test_reshaped = reshape_for_ann(y_test_scaled)\n",
    "    \n",
    "    sensor_params['m'] = m\n",
    "    sensor_params['n'] = n\n",
    "\n",
    "    sensors, sensor_params = get_sensor_data(y_train_reshaped, sensor_params)\n",
    "    sensors_test, _ = get_sensor_data(y_test_reshaped, sensor_params)\n",
    "\n",
    "    sensors = reshape_for_ann(sensors)\n",
    "    sensors_test = reshape_for_ann(sensors_test)\n",
    "\n",
    "    unseen_filename = '../data/primitives/diamond_ar_2p0/w_z.npy'\n",
    "    unseen_y = np.load(unseen_filename)\n",
    "    unseen_y = unseen_y[100:,:,:]\n",
    "    unseen_y = np.transpose(unseen_y, (0, 2, 1))\n",
    "    \n",
    "    unseen_y_scaled, _, _ = rescale_data(unseen_y, None, scaling_params=scaling_params)\n",
    "    unseen_y_reshaped = reshape_for_ann(unseen_y_scaled)\n",
    "    unseen_sensors, _ = get_sensor_data(unseen_y_reshaped, sensor_params)\n",
    "    unseen_sensors = reshape_for_ann(unseen_sensors)\n",
    "    \n",
    "    model = POD(plus=True)\n",
    "    model.summary()\n",
    "    sensor_locations = sensor_params['pivots']\n",
    "    model.fit(\n",
    "        sensors.reshape(sensors.shape[0],-1),\n",
    "        y_train.reshape(y_train.shape[0],-1),\n",
    "        sensor_locations,\n",
    "        alpha=1e-8\n",
    "    )\n",
    "    prediction = model.predict(unseen_sensors.reshape(unseen_sensors.shape[0],-1))\n",
    "\n",
    "    prediction = prediction.reshape(prediction.shape[0],m,n)\n",
    "    prediction_inv_scaled = unscale_data(prediction, scaling_params)\n",
    "\n",
    "    upstream_mask = sensor_params.get('upstream_mask')\n",
    "    img_per_pixel_abs_error = np.abs(prediction_inv_scaled - unseen_y) * upstream_mask\n",
    "    img_overall_l2_error = calculate_l2_error_norm(prediction_inv_scaled * upstream_mask, unseen_y * upstream_mask)\n",
    "\n",
    "    mins.append(img_overall_l2_error.min())\n",
    "    maxs.append(img_overall_l2_error.max())\n",
    "    means.append(img_overall_l2_error.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "directed-belief",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 100.04\\% & 100.04\\% & 100.04\\% \\\\\n",
      "& 100.27\\% & 100.27\\% & 100.27\\% \\\\\n",
      "& 101.19\\% & 101.19\\% & 101.19\\% \\\\\n",
      "& 100.76\\% & 100.76\\% & 100.76\\% \\\\\n",
      "& 102.05\\% & 102.05\\% & 102.05\\% \\\\\n",
      "& 98.56\\% & 98.56\\% & 98.56\\% \\\\\n",
      "& 93.99\\% & 93.99\\% & 93.99\\% \\\\\n",
      "& 97.24\\% & 97.24\\% & 97.24\\% \\\\\n",
      "& 96.45\\% & 96.46\\% & 96.46\\% \\\\\n",
      "& 100.26\\% & 100.26\\% & 100.26\\% \\\\\n",
      "& 100.60\\% & 100.60\\% & 100.60\\% \\\\\n",
      "& 100.39\\% & 100.39\\% & 100.39\\% \\\\\n",
      "& 101.19\\% & 101.19\\% & 101.19\\% \\\\\n",
      "& 100.53\\% & 100.53\\% & 100.53\\% \\\\\n",
      "& 100.02\\% & 100.02\\% & 100.02\\% \\\\\n",
      "& 100.00\\% & 100.00\\% & 100.00\\% \\\\\n",
      "& 99.99\\% & 99.99\\% & 99.99\\% \\\\\n",
      "& 99.99\\% & 99.99\\% & 99.99\\% \\\\\n",
      "& 97.25\\% & 97.25\\% & 97.25\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(mins)):\n",
    "    print(f'& {mins[i]*100:.2f}\\% & {maxs[i]*100:.2f}\\% & {means[i]*100:.2f}\\% \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-driver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
